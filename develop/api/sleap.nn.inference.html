

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>sleap.nn.inference &#8212; SLEAP (v1.4.1a2)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tabs.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/sleap.nn.inference';</script>
    <link rel="canonical" href="/develop/api/sleap.nn.inference.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/tutorial.html">Tutorial</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/new-project.html">Creating a project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/initial-labeling.html">Initial Labeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/initial-training.html">Training and Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/assisted-labeling.html">Prediction-assisted labeling</a></li>

<li class="toctree-l2"><a class="reference internal" href="../tutorials/proofreading.html">Tracking instances across frames</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/analysis.html">Export Data For Analysis</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../guides/index.html">Guides</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../guides/gui.html">GUI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/cli.html">Command line interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/troubleshooting-workflows.html">Troubleshooting workflows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/skeletons.html">Skeleton design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/choosing-models.html">Configuring models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/merging.html">Importing predictions for labeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/proofreading.html">Tracking and proofreading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/colab.html">Run training and inference on Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/custom-training.html">Creating a custom training profile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/remote.html">Running SLEAP remotely</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/index.html">Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/Training_and_inference_on_an_example_dataset.html">Training and inference on an example dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/Training_and_inference_using_Google_Drive.html">Training and inference on your own data using Google Drive</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/Model_evaluation.html">Model evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/Analysis_examples.html">Analysis examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/Data_structures.html">Data structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/Post_inference_tracking.html">Post-inference tracking</a></li>



<li class="toctree-l2"><a class="reference internal" href="../notebooks/Interactive_and_resumable_training.html">Interactive and resumable training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/Interactive_and_realtime_inference.html">Interactive and realtime inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api.html">Developer API</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/talmolab/sleap">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/talmolab/sleap/releases">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../help.html">Help</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/talmolab/sleap" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/talmolab/sleap/issues/new?title=Issue%20on%20page%20%2Fapi/sleap.nn.inference.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>sleap.nn.inference</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.paf_scorer"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.paf_scorer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.cm_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.cm_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.paf_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.paf_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.return_confmaps"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.return_pafs"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_pafs</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.return_paf_graph"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_paf_graph</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.pafs_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.pafs_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.offsets_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.find_peaks"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.find_peaks()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.forward_pass"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.forward_pass()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceModel"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceModel.bottomup_layer"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceModel.bottomup_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.cm_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.cm_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.class_maps_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_confmaps"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_class_maps"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.return_class_maps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.class_maps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.offsets_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.find_peaks"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.find_peaks()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.forward_pass"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.forward_pass()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel.inference_layer"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceModel.inference_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.config"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.model"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.tracks"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.tracks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.bottomup_config"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.bottomup_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.bottomup_model"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.bottomup_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.tracker"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.tracker</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.max_edge_length_ratio"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.max_edge_length_ratio</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.dist_penalty_weight"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.dist_penalty_weight</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.paf_line_points"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.paf_line_points</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.min_line_scores"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.min_line_scores</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.max_instances"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.max_instances</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop"><code class="docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.keras_model"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.crop_size"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.crop_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.input_scale"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.output_stride"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.peak_threshold"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.refinement"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.return_confmaps"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.offsets_ind"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.return_crops"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.return_crops</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.max_instances"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.max_instances</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.call"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCropGroundTruth"><code class="docutils literal notranslate"><span class="pre">CentroidCropGroundTruth</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCropGroundTruth.crop_size"><code class="docutils literal notranslate"><span class="pre">CentroidCropGroundTruth.crop_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCropGroundTruth.call"><code class="docutils literal notranslate"><span class="pre">CentroidCropGroundTruth.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidInferenceModel"><code class="docutils literal notranslate"><span class="pre">CentroidInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidInferenceModel.centroid_crop"><code class="docutils literal notranslate"><span class="pre">CentroidInferenceModel.centroid_crop</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">CentroidInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.keras_model"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.input_scale"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.output_stride"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.peak_threshold"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.refinement"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.return_confmaps"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.offsets_ind"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.call"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaksGroundTruth"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaksGroundTruth</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaksGroundTruth.call"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaksGroundTruth.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer"><code class="docutils literal notranslate"><span class="pre">InferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.ensure_grayscale"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.ensure_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.ensure_float"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.ensure_float</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.preprocess"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.preprocess()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel"><code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel.export_model"><code class="docutils literal notranslate"><span class="pre">InferenceModel.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel.predict"><code class="docutils literal notranslate"><span class="pre">InferenceModel.predict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel.predict_on_batch"><code class="docutils literal notranslate"><span class="pre">InferenceModel.predict_on_batch()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.model_name"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.model_name</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.ensure_grayscale"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.ensure_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.ensure_float"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.ensure_float</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceModel"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceModel.inference_layer"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceModel.inference_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.model_name"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.model_name</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor"><code class="docutils literal notranslate"><span class="pre">Predictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.export_model"><code class="docutils literal notranslate"><span class="pre">Predictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.from_model_paths"><code class="docutils literal notranslate"><span class="pre">Predictor.from_model_paths()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">Predictor.is_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">Predictor.make_pipeline()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.predict"><code class="docutils literal notranslate"><span class="pre">Predictor.predict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.report_period"><code class="docutils literal notranslate"><span class="pre">Predictor.report_period</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.RateColumn"><code class="docutils literal notranslate"><span class="pre">RateColumn</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.RateColumn.render"><code class="docutils literal notranslate"><span class="pre">RateColumn.render()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.output_stride"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.peak_threshold"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.refinement"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.return_confmaps"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.offsets_ind"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceModel"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceModel.single_instance_layer"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceModel.single_instance_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.confmap_config"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.confmap_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.confmap_model"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.confmap_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.export_model"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel.centroid_crop"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel.centroid_crop</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel.instance_peaks"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel.instance_peaks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.keras_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.input_scale"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.output_stride"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.peak_threshold"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.refinement"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_confmaps"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_class_vectors"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.return_class_vectors</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.offsets_ind"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.class_vectors_ind"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.class_vectors_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.optimal_grouping"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.optimal_grouping</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.call"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.centroid_crop"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.centroid_crop</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.instance_peaks"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.instance_peaks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.export_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.export_model()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.centroid_config"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.centroid_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.centroid_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.centroid_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.confmap_config"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.confmap_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.confmap_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.confmap_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.tracker"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.tracker</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.tracks"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.tracks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.export_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.is_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.make_pipeline()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.centroid_config"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.centroid_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.centroid_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.centroid_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.confmap_config"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.confmap_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.confmap_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.confmap_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.tracker"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.tracker</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.max_instances"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.max_instances</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.export_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.is_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.make_pipeline()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor"><code class="docutils literal notranslate"><span class="pre">VisualPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">VisualPredictor.make_pipeline()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor.predict"><code class="docutils literal notranslate"><span class="pre">VisualPredictor.predict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor.safely_generate"><code class="docutils literal notranslate"><span class="pre">VisualPredictor.safely_generate()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.export_cli"><code class="docutils literal notranslate"><span class="pre">export_cli()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.export_model"><code class="docutils literal notranslate"><span class="pre">export_model()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.find_head"><code class="docutils literal notranslate"><span class="pre">find_head()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.get_keras_model_path"><code class="docutils literal notranslate"><span class="pre">get_keras_model_path()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.get_model_output_stride"><code class="docutils literal notranslate"><span class="pre">get_model_output_stride()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.main"><code class="docutils literal notranslate"><span class="pre">main()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.make_model_movenet"><code class="docutils literal notranslate"><span class="pre">make_model_movenet()</span></code></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="module-sleap.nn.inference">
<span id="sleap-nn-inference"></span><h1>sleap.nn.inference<a class="headerlink" href="#module-sleap.nn.inference" title="Permalink to this heading">#</a></h1>
<p>Inference pipelines and utilities.</p>
<p>This module contains the classes and high level APIs for predicting instances on new
data using trained models.</p>
<p>The inference logic is implemented at two levels:</p>
<ul class="simple">
<li><p>Low-level <code class="xref py py-obj docutils literal notranslate"><span class="pre">InferenceModel`s</span> <span class="pre">which</span> <span class="pre">subclass</span> <span class="pre">`tf.keras.Model</span></code> and implement the core
TensorFlow operations surrounding inference. These should only be used when
implementing custom inference routines, such as real-time or performance-critical
applications. They do not implement tracking (identity association).</p></li>
<li><p>High-level <a href="#id1"><span class="problematic" id="id2">`</span></a>Predictor`s which handle data loading, preprocessing, inference, tracking
and postprocessing, including converting raw array results into SLEAP-specific data
structures. These should be used for general-purpose prediction, including interactive
inference and applications that require tracking (identity association).</p></li>
</ul>
<p>For more information on tracking, see the <a class="reference internal" href="sleap.nn.tracking.html#module-sleap.nn.tracking" title="sleap.nn.tracking"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.tracking</span></code></a> module.</p>
<p>The recommended high-level API for loading saved models is the <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.load_models</span></code>
function which provides a simplified interface for creating <a href="#id3"><span class="problematic" id="id4">`</span></a>Predictor`s.</p>
<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">BottomUpInferenceLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2695-L2961"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Keras layer that predicts instances from images using a trained model.</p>
<p>This layer encapsulates all of the inference operations required for generating
predictions from a centered instance confidence map model. This includes
preprocessing, model forward pass, peak finding and coordinate adjustment.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that accepts rank-4 images as input and predicts
rank-4 confidence maps and part affinity fields as output.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.paf_scorer">
<span class="sig-name descname"><span class="pre">paf_scorer</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.paf_scorer" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.paf_grouping.html#sleap.nn.paf_grouping.PAFScorer" title="sleap.nn.paf_grouping.PAFScorer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.paf_grouping.PAFScorer</span></code></a> instance configured to group
instances based on peaks and PAFs produced by the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>Float indicating if the images should be resized before being
passed to the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.cm_output_stride">
<span class="sig-name descname"><span class="pre">cm_output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.cm_output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the output
confidence maps relative to the images (after input scaling). This is used
for adjusting the peak coordinates to the image grid. This will be inferred
from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.paf_output_stride">
<span class="sig-name descname"><span class="pre">paf_output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.paf_output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the output
part affinity fields relative to the images (after input scaling). This is
used for adjusting the peak coordinates to the PAF grid. This will be
inferred from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.refinement">
<span class="sig-name descname"><span class="pre">refinement</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, returns the grid-aligned peaks with no refinement. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;integral&quot;</span></code>, peaks will be refined with integral regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>,
peaks will be refined with quarter pixel local gradient offset. This has no
effect if the model has an offset regression head.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.return_confmaps">
<span class="sig-name descname"><span class="pre">return_confmaps</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.return_confmaps" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the confidence maps will be returned together with
the predicted instances. This will result in slower inference times since
the data must be copied off of the GPU, but is useful for visualizing the
raw output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.return_pafs">
<span class="sig-name descname"><span class="pre">return_pafs</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.return_pafs" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the part affinity fields will be returned together with
the predicted instances. This will result in slower inference times since
the data must be copied off of the GPU, but is useful for visualizing the
raw output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.return_paf_graph">
<span class="sig-name descname"><span class="pre">return_paf_graph</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.return_paf_graph" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the part affinity field graph will be returned
together with the predicted instances. The graph is obtained by parsing the
part affinity fields with the <a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceLayer.paf_scorer" title="sleap.nn.inference.BottomUpInferenceLayer.paf_scorer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">paf_scorer</span></code></a> instance and is an intermediate
representation used during instance grouping.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.confmaps_ind">
<span class="sig-name descname"><span class="pre">confmaps_ind</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.confmaps_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
confidence maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;MultiInstanceConfmapsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.pafs_ind">
<span class="sig-name descname"><span class="pre">pafs_ind</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.pafs_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to part affinity
fields. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected automatically by
searching for the first tensor that contains <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;PartAffinityFieldsHead&quot;</span></code> in
its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.offsets_ind">
<span class="sig-name descname"><span class="pre">offsets_ind</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.offsets_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
offset regression maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;OffsetRefinementHead&quot;</span></code> in its name. If the head is not present, the method
specified in the <a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceLayer.refinement" title="sleap.nn.inference.BottomUpInferenceLayer.refinement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">refinement</span></code></a> attribute will be used.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2896-L2961"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong>  This may be either a single batch of images as a 4-D tensor of shape</p></li>
<li><p><strong>`</strong> (<em>batch_size</em><em>, </em><em>height</em><em>, </em><em>width</em><em>, </em><em>channels</em>)  </p></li>
<li><p><strong>key.</strong> (<em>image batch in the &quot;images&quot;</em>)  </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: Instance skeleton
points.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes)</span></code>: Confidence
values for the instance skeleton points.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_scores&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances)</span></code>: PAF matching score for each
instance.</p>
<p>If <a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceLayer.return_confmaps" title="sleap.nn.inference.BottomUpInferenceLayer.return_confmaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_confmaps</span></code></a> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the predicted
confidence maps will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;confmaps&quot;</span></code> key.</p>
<p>If <a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceLayer.return_pafs" title="sleap.nn.inference.BottomUpInferenceLayer.return_pafs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_pafs</span></code></a> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the predicted PAFs will
be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;part_affinity_fields&quot;</span></code> key.</p>
<p>If <a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceLayer.return_paf_graph" title="sleap.nn.inference.BottomUpInferenceLayer.return_paf_graph"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_paf_graph</span></code></a> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the predicted PAF
graph will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;peaks&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;peak_vals&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;peak_channel_inds&quot;</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;edge_inds&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;edge_peak_inds&quot;</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;line_scores&quot;</span></code> keys.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.find_peaks">
<span class="sig-name descname"><span class="pre">find_peaks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cms</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2850-L2894"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.find_peaks" title="Permalink to this definition">#</a></dt>
<dd><p>Run peak finding on predicted confidence maps.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceLayer.forward_pass">
<span class="sig-name descname"><span class="pre">forward_pass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2822-L2848"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceLayer.forward_pass" title="Permalink to this definition">#</a></dt>
<dd><p>Run preprocessing and model inference on a batch.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">BottomUpInferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2964-L3010"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>Bottom-up instance prediction model.</p>
<p>This model encapsulates the bottom-up approach where points are first detected by
local peak detection and then grouped into instances by connectivity scoring using
part affinity fields.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceModel.bottomup_layer">
<span class="sig-name descname"><span class="pre">bottomup_layer</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceModel.bottomup_layer" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceLayer" title="sleap.nn.inference.BottomUpInferenceLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpInferenceLayer</span></code></a>. This layer takes as input a full
image and outputs the predicted instances.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpInferenceModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2984-L3010"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpInferenceModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example</strong>  This may be either a single batch of images as a 4-D tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code>, or a dictionary
containing the image batch in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;images&quot;</span></code> key.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: Instance skeleton</dt><dd><p>points.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes)</span></code>: Confidence</dt><dd><p>values for the instance skeleton points.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_scores&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances)</span></code>: PAF matching score for each</dt><dd><p>instance.</p>
</dd>
</dl>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpInferenceModel.bottomup_layer.return_confmaps</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the
predicted confidence maps will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;confmaps&quot;</span></code> key.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpInferenceModel.bottomup_layer.return_pafs</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the
predicted PAFs will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;part_affinity_fields&quot;</span></code> key.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">BottomUpMultiClassInferenceLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3309-L3547"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Keras layer that predicts instances from images using a trained model.</p>
<p>This layer encapsulates all of the inference operations required for generating
predictions from a centered instance confidence map model. This includes
preprocessing, model forward pass, peak finding and coordinate adjustment.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that accepts rank-4 images as input and predicts
rank-4 confidence maps and class maps as output.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>Float indicating if the images should be resized before being
passed to the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.cm_output_stride">
<span class="sig-name descname"><span class="pre">cm_output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.cm_output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the output
confidence maps relative to the images (after input scaling). This is used
for adjusting the peak coordinates to the image grid. This will be inferred
from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_output_stride">
<span class="sig-name descname"><span class="pre">class_maps_output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the
output class maps relative to the images (after input scaling). This is
used for adjusting the peak coordinates to the class maps grid. This will be
inferred from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.refinement">
<span class="sig-name descname"><span class="pre">refinement</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, returns the grid-aligned peaks with no refinement. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;integral&quot;</span></code>, peaks will be refined with integral regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>,
peaks will be refined with quarter pixel local gradient offset. This has no
effect if the model has an offset regression head.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_confmaps">
<span class="sig-name descname"><span class="pre">return_confmaps</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_confmaps" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the confidence maps will be returned together with
the predicted instances. This will result in slower inference times since
the data must be copied off of the GPU, but is useful for visualizing the
raw output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_class_maps">
<span class="sig-name descname"><span class="pre">return_class_maps</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_class_maps" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the class maps will be returned together with
the predicted instances. This will result in slower inference times since
the data must be copied off of the GPU, but is useful for visualizing the
raw output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.confmaps_ind">
<span class="sig-name descname"><span class="pre">confmaps_ind</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.confmaps_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
confidence maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;MultiInstanceConfmapsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_ind">
<span class="sig-name descname"><span class="pre">class_maps_ind</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to class
maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected automatically by
searching for the first tensor that contains <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;ClassMapsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.offsets_ind">
<span class="sig-name descname"><span class="pre">offsets_ind</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.offsets_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
offset regression maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;OffsetRefinementHead&quot;</span></code> in its name. If the head is not present, the method
specified in the <a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.refinement" title="sleap.nn.inference.BottomUpMultiClassInferenceLayer.refinement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">refinement</span></code></a> attribute will be used.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3483-L3547"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong>  This may be either a single batch of images as a 4-D tensor of shape</p></li>
<li><p><strong>`</strong> (<em>batch_size</em><em>, </em><em>height</em><em>, </em><em>width</em><em>, </em><em>channels</em>)  </p></li>
<li><p><strong>key.</strong> (<em>image batch in the &quot;images&quot;</em>)  </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: Instance skeleton
points.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes)</span></code>: Confidence
values for the instance skeleton points.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_scores&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances)</span></code>: PAF matching score for each
instance.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">inference_layer.return_confmaps</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the predicted confidence
maps will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;confmaps&quot;</span></code> key.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">inference_layer.return_class_maps</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the predicted class maps
will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;class_maps&quot;</span></code> key.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.find_peaks">
<span class="sig-name descname"><span class="pre">find_peaks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cms</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3451-L3481"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.find_peaks" title="Permalink to this definition">#</a></dt>
<dd><p>Run peak finding on predicted confidence maps.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceLayer.forward_pass">
<span class="sig-name descname"><span class="pre">forward_pass</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3425-L3449"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.forward_pass" title="Permalink to this definition">#</a></dt>
<dd><p>Run preprocessing and model inference on a batch.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">BottomUpMultiClassInferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3550-L3592"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>Bottom-up multi-class instance prediction model.</p>
<p>This model encapsulates the bottom-up multi-class approach where points are first
detected by local peak finding and then grouped into instances by their identity
classifications.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceModel.inference_layer">
<span class="sig-name descname"><span class="pre">inference_layer</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel.inference_layer" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer" title="sleap.nn.inference.BottomUpMultiClassInferenceLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer</span></code></a>. This layer takes as input
a full image and outputs the predicted instances.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassInferenceModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3566-L3592"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example</strong>  This may be either a single batch of images as a 4-D tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code>, or a dictionary
containing the image batch in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;images&quot;</span></code> key.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: Instance skeleton</dt><dd><p>points.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes)</span></code>: Confidence</dt><dd><p>values for the instance skeleton points.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_scores&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances)</span></code>: PAF matching score for each</dt><dd><p>instance.</p>
</dd>
</dl>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">inference_layer.return_confmaps</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the predicted confidence
maps will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;confmaps&quot;</span></code> key.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">inference_layer.return_class_maps</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the predicted class maps
will be returned in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;class_maps&quot;</span></code> key.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">BottomUpMultiClassPredictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel" title="sleap.nn.inference.BottomUpMultiClassInferenceModel"><span class="pre">BottomUpMultiClassInferenceModel</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.instance.html#sleap.instance.Track" title="sleap.instance.Track"><span class="pre">Track</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3596-L3817"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor" title="Permalink to this definition">#</a></dt>
<dd><p>Bottom-up multi-instance predictor.</p>
<p>This high-level class handles initialization, preprocessing and tracking using a
trained bottom-up multi-instance SLEAP model.</p>
<p>This should be initialized using the <a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassPredictor.from_trained_models" title="sleap.nn.inference.BottomUpMultiClassPredictor.from_trained_models"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_trained_models()</span></code></a> constructor or the
high-level API (<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.load_model</span></code>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.config">
<span class="sig-name descname"><span class="pre">config</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.config" title="Permalink to this definition">#</a></dt>
<dd><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.config.TrainingJobConfig</span></code> containing the metadata for the
trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig">sleap.nn.config.training_job.TrainingJobConfig</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.model.Model</span></code></a> instance created from the trained model. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth centroids will be used if available from the data
source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model">sleap.nn.model.Model</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.inference_model">
<span class="sig-name descname"><span class="pre">inference_model</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.inference_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel" title="sleap.nn.inference.BottomUpMultiClassInferenceModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.inference.BottomUpMultiClassInferenceModel</span></code></a> that
wraps a trained <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> to implement preprocessing, peak finding
and classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel" title="sleap.nn.inference.BottomUpMultiClassInferenceModel">sleap.nn.inference.BottomUpMultiClassInferenceModel</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.pipeline">
<span class="sig-name descname"><span class="pre">pipeline</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.data.Pipeline</span></code> that loads the data and batches input data.
This will be updated dynamically if new data sources are used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline">sleap.nn.data.pipelines.Pipeline</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.batch_size" title="Permalink to this definition">#</a></dt>
<dd><p>The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a local peak as valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.integral_refinement">
<span class="sig-name descname"><span class="pre">integral_refinement</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.integral_refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral regression.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter pixel local
gradient offset. This has no effect if the model has an offset regression
head.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.tracks">
<span class="sig-name descname"><span class="pre">tracks</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.tracks" title="Permalink to this definition">#</a></dt>
<dd><p>If provided, instances will be created using these track instances. If
not, instances will be assigned tracks from the provider if possible.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[List[<a class="reference internal" href="sleap.instance.html#sleap.instance.Track" title="sleap.instance.Track">sleap.instance.Track</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.from_trained_models">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_trained_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resize_input_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassPredictor" title="sleap.nn.inference.BottomUpMultiClassPredictor"><span class="pre">BottomUpMultiClassPredictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3654-L3705"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.from_trained_models" title="Permalink to this definition">#</a></dt>
<dd><p>Create predictor from a saved model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong>  Path to a model folder or training job JSON file inside a model
folder. This folder should contain <code class="xref py py-obj docutils literal notranslate"><span class="pre">training_config.json</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> files for a trained model.</p></li>
<li><p><strong>batch_size</strong>  The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory
usage.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a local peak as
valid.</p></li>
<li><p><strong>integral_refinement</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral
regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter
pixel local gradient offset. This has no effect if the model has an
offset regression head.</p></li>
<li><p><strong>integral_patch_size</strong>  Size of patches to crop around each rough peak for
integral refinement as an integer scalar.</p></li>
<li><p><strong>resize_input_layer</strong>  If True, the the input layer of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Keras.model</span></code> is
resized to (None, None, None, num_color_channels).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of <a class="reference internal" href="#sleap.nn.inference.BottomUpPredictor" title="sleap.nn.inference.BottomUpPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpPredictor</span></code></a> with the loaded model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpMultiClassPredictor.is_grayscale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_grayscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#sleap.nn.inference.BottomUpMultiClassPredictor.is_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Return whether the model expects grayscale inputs.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">BottomUpPredictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bottomup_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">bottomup_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceModel" title="sleap.nn.inference.BottomUpInferenceModel"><span class="pre">BottomUpInferenceModel</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_edge_length_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_penalty_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paf_line_points</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_line_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3014-L3306"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor" title="Permalink to this definition">#</a></dt>
<dd><p>Bottom-up multi-instance predictor.</p>
<p>This high-level class handles initialization, preprocessing and tracking using a
trained bottom-up multi-instance SLEAP model.</p>
<p>This should be initialized using the <a class="reference internal" href="#sleap.nn.inference.BottomUpPredictor.from_trained_models" title="sleap.nn.inference.BottomUpPredictor.from_trained_models"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_trained_models()</span></code></a> constructor or the
high-level API (<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.load_model</span></code>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.bottomup_config">
<span class="sig-name descname"><span class="pre">bottomup_config</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.bottomup_config" title="Permalink to this definition">#</a></dt>
<dd><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.config.TrainingJobConfig</span></code> containing the metadata
for the trained bottomup model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig">sleap.nn.config.training_job.TrainingJobConfig</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.bottomup_model">
<span class="sig-name descname"><span class="pre">bottomup_model</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.bottomup_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.model.Model</span></code></a> instance created from the trained
bottomup model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth centroids will be used if available
from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model">sleap.nn.model.Model</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.inference_model">
<span class="sig-name descname"><span class="pre">inference_model</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.inference_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceModel" title="sleap.nn.inference.BottomUpInferenceModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.inference.BottomUpInferenceModel</span></code></a> that wraps a
trained <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> to implement preprocessing, centroid detection,
cropping and peak finding.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#sleap.nn.inference.BottomUpInferenceModel" title="sleap.nn.inference.BottomUpInferenceModel">sleap.nn.inference.BottomUpInferenceModel</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.pipeline">
<span class="sig-name descname"><span class="pre">pipeline</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.data.Pipeline</span></code> that loads the data and batches input data.
This will be updated dynamically if new data sources are used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline">sleap.nn.data.pipelines.Pipeline</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.tracker">
<span class="sig-name descname"><span class="pre">tracker</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.tracker" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.tracking.html#sleap.nn.tracking.Tracker" title="sleap.nn.tracking.Tracker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.tracking.Tracker</span></code></a> that will be called to associate
detections over time. Predicted instances will not be assigned to tracks if
if this is <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.tracking.html#sleap.nn.tracking.Tracker" title="sleap.nn.tracking.Tracker">sleap.nn.tracking.Tracker</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.batch_size" title="Permalink to this definition">#</a></dt>
<dd><p>The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a local peak as valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.integral_refinement">
<span class="sig-name descname"><span class="pre">integral_refinement</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.integral_refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral regression.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter pixel local
gradient offset. This has no effect if the model has an offset regression
head.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.max_edge_length_ratio">
<span class="sig-name descname"><span class="pre">max_edge_length_ratio</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.max_edge_length_ratio" title="Permalink to this definition">#</a></dt>
<dd><p>The maximum expected length of a connected pair of points
as a fraction of the image size. Candidate connections longer than this
length will be penalized during matching.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.dist_penalty_weight">
<span class="sig-name descname"><span class="pre">dist_penalty_weight</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.dist_penalty_weight" title="Permalink to this definition">#</a></dt>
<dd><p>A coefficient to scale weight of the distance penalty as
a scalar float. Set to values greater than 1.0 to enforce the distance
penalty more strictly.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.paf_line_points">
<span class="sig-name descname"><span class="pre">paf_line_points</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.paf_line_points" title="Permalink to this definition">#</a></dt>
<dd><p>Number of points to sample along the line integral.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.min_line_scores">
<span class="sig-name descname"><span class="pre">min_line_scores</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.min_line_scores" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum line score (between -1 and 1) required to form a match
between candidate point pairs. Useful for rejecting spurious detections when
there are no better ones.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.max_instances">
<span class="sig-name descname"><span class="pre">max_instances</span></span><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.max_instances" title="Permalink to this definition">#</a></dt>
<dd><p>If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, discard instances beyond this count when
predicting, regardless of whether filtering is done at the tracking stage.
This is useful for preventing extraneous instances from being created when
tracking is not being applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.from_trained_models">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_trained_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_edge_length_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_penalty_weight</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paf_line_points</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_line_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resize_input_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.BottomUpPredictor" title="sleap.nn.inference.BottomUpPredictor"><span class="pre">BottomUpPredictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3109-L3186"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.from_trained_models" title="Permalink to this definition">#</a></dt>
<dd><p>Create predictor from a saved model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong>  Path to a bottom-up model folder or training job JSON file
inside a model folder. This folder should contain <code class="xref py py-obj docutils literal notranslate"><span class="pre">training_config.json</span></code>
and <code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> files for a trained model.</p></li>
<li><p><strong>batch_size</strong>  The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory
usage.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a local peak as
valid.</p></li>
<li><p><strong>integral_refinement</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral
regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter
pixel local gradient offset. This has no effect if the model has an
offset regression head.</p></li>
<li><p><strong>integral_patch_size</strong>  Size of patches to crop around each rough peak for
integral refinement as an integer scalar.</p></li>
<li><p><strong>max_edge_length_ratio</strong>  The maximum expected length of a connected pair of
points as a fraction of the image size. Candidate connections longer
than this length will be penalized during matching.</p></li>
<li><p><strong>dist_penalty_weight</strong>  A coefficient to scale weight of the distance penalty
as a scalar float. Set to values greater than 1.0 to enforce the
distance penalty more strictly.</p></li>
<li><p><strong>paf_line_points</strong>  Number of points to sample along the line integral.</p></li>
<li><p><strong>min_line_scores</strong>  Minimum line score (between -1 and 1) required to form a
match between candidate point pairs. Useful for rejecting spurious
detections when there are no better ones.</p></li>
<li><p><strong>resize_input_layer</strong>  If True, the the input layer of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Keras.model</span></code> is
resized to (None, None, None, num_color_channels).</p></li>
<li><p><strong>max_instances</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, discard instances beyond this count when
predicting, regardless of whether filtering is done at the tracking
stage. This is useful for preventing extraneous instances from being
created when tracking is not being applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of <a class="reference internal" href="#sleap.nn.inference.BottomUpPredictor" title="sleap.nn.inference.BottomUpPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpPredictor</span></code></a> with the loaded model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.BottomUpPredictor.is_grayscale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_grayscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#sleap.nn.inference.BottomUpPredictor.is_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Return whether the model expects grayscale inputs.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">CentroidCrop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1625-L1941"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.CentroidCrop" title="Permalink to this definition">#</a></dt>
<dd><p>Inference layer for applying centroid crop-based models.</p>
<p>This layer encapsulates all of the inference operations requires for generating
predictions from a centroid confidence map model. This includes preprocessing,
model forward pass, peak finding, coordinate adjustment and cropping.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that accepts rank-4 images as input and predicts
rank-4 confidence maps as output. This should be a model that is trained on
centroid/anchor confidence maps.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.crop_size">
<span class="sig-name descname"><span class="pre">crop_size</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.crop_size" title="Permalink to this definition">#</a></dt>
<dd><p>Integer scalar specifying the height/width of the centered crops.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>Float indicating if the images should be resized before being
passed to the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.pad_to_stride">
<span class="sig-name descname"><span class="pre">pad_to_stride</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.pad_to_stride" title="Permalink to this definition">#</a></dt>
<dd><p>If not 1, input image will be paded to ensure that it is
divisible by this value (after scaling). This should be set to the max
stride of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.output_stride">
<span class="sig-name descname"><span class="pre">output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the output
confidence maps relative to the images (after input scaling). This is used
for adjusting the peak coordinates to the image grid. This will be inferred
from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.refinement">
<span class="sig-name descname"><span class="pre">refinement</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, returns the grid-aligned peaks with no refinement. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;integral&quot;</span></code>, peaks will be refined with integral regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>,
peaks will be refined with quarter pixel local gradient offset. This has no
effect if the model has an offset regression head.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.return_confmaps">
<span class="sig-name descname"><span class="pre">return_confmaps</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.return_confmaps" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the confidence maps will be returned together with
the predicted peaks. This will result in slower inference times since the
data must be copied off of the GPU, but is useful for visualizing the raw
output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.confmaps_ind">
<span class="sig-name descname"><span class="pre">confmaps_ind</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.confmaps_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
confidence maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;CentroidConfmapsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.offsets_ind">
<span class="sig-name descname"><span class="pre">offsets_ind</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.offsets_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
offset regression maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;OffsetRefinementHead&quot;</span></code> in its name. If the head is not present, the method
specified in the <a class="reference internal" href="#sleap.nn.inference.CentroidCrop.refinement" title="sleap.nn.inference.CentroidCrop.refinement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">refinement</span></code></a> attribute will be used.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.return_crops">
<span class="sig-name descname"><span class="pre">return_crops</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.return_crops" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the crops and offsets will be returned together with
the predicted peaks. This is true by default since crops are used
for finding instance peaks in a top down model. If using a centroid
only inference model, this should be set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.max_instances">
<span class="sig-name descname"><span class="pre">max_instances</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.max_instances" title="Permalink to this definition">#</a></dt>
<dd><p>If set, determines the max number of instances that a
multi-instance model returns.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCrop.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#sleap.nn.inference.CentroidCrop.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict centroid confidence maps and crop around peaks.</p>
<p>This layer can be chained with a <a class="reference internal" href="#sleap.nn.inference.FindInstancePeaks" title="sleap.nn.inference.FindInstancePeaks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FindInstancePeaks</span></code></a> layer to create a top-down
inference function from full images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong>  Full frame images as a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code> or a dictionary with key:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;image&quot;</span></code>: Full frame images in the same format as above.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;</span></code>: The predicted centroids of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">2)</span></code>.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;:</span> <span class="pre">The</span> <span class="pre">centroid</span> <span class="pre">confidence</span> <span class="pre">values</span> <span class="pre">of</span> <span class="pre">shape</span> <span class="pre">`(samples,</span> <span class="pre">?)</span></code>.</p>
<p>If the <a class="reference internal" href="#sleap.nn.inference.CentroidCrop.return_confmaps" title="sleap.nn.inference.CentroidCrop.return_confmaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">return_confmaps</span></code></a> attribute is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the output will also
contain a key named <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_confmaps&quot;</span></code> containing a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">output_height,</span> <span class="pre">output_width,</span> <span class="pre">1)</span></code> containing the
confidence maps predicted by the model.</p>
<p>If the <a class="reference internal" href="#sleap.nn.inference.CentroidCrop.return_crops" title="sleap.nn.inference.CentroidCrop.return_crops"><code class="xref py py-obj docutils literal notranslate"><span class="pre">return_crops</span></code></a> attribute is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the output will
also contain keys named <code class="xref py py-obj docutils literal notranslate"><span class="pre">crops</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">crop_offsets</span></code>. The former is a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of cropped images of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span>
<span class="pre">crop_size,</span> <span class="pre">crop_size,</span> <span class="pre">channels)</span></code>. The latter is a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code>
of Coordinates of the top-left of the crops as <code class="xref py py-obj docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y)</span></code> offsets of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">2)</span></code> for adjusting the predicted peak
coordinates.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A dictionary of outputs grouped by sample with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCropGroundTruth">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">CentroidCropGroundTruth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L723-L799"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.CentroidCropGroundTruth" title="Permalink to this definition">#</a></dt>
<dd><p>Keras layer that simulates a centroid cropping model using ground truth.</p>
<p>This layer is useful for testing and evaluating centered instance models.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCropGroundTruth.crop_size">
<span class="sig-name descname"><span class="pre">crop_size</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidCropGroundTruth.crop_size" title="Permalink to this definition">#</a></dt>
<dd><p>The length of the square box to extract around each centroid.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidCropGroundTruth.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example_gt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L736-L799"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.CentroidCropGroundTruth.call" title="Permalink to this definition">#</a></dt>
<dd><p>Return the ground truth instance crops.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example_gt</strong>  <p>Dictionary generated from a labels pipeline with the keys:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;image&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">2)</span></code>: The input centroids.</p>
<blockquote>
<div><p>Axis 1 is expected to be ragged.</p>
</div></blockquote>
<p>These can be generated by the <code class="xref py py-obj docutils literal notranslate"><span class="pre">InstanceCentroidFinder</span></code> transformer.</p>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;crops&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">crop_size,</span> <span class="pre">crop_size,</span> <span class="pre">channels)</span></code>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;crop_offsets&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">crop_size,</span> <span class="pre">crop_size,</span> <span class="pre">channels)</span></code></p>
<blockquote>
<div><p>These contain the top-left coordinates of each crop in the full images.</p>
</div></blockquote>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">2)</span></code>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids)</span></code></p>
<p>Axis 1 of all keys are expected to be ragged.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;</span></code> are from the input example and <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;</span></code> will be
filled with ones.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing the output of the instance cropping layer with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidInferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">CentroidInferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2169-L2209"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.CentroidInferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>Centroid only instance prediction model.</p>
<p>This model encapsulates the first step in a top-down approach where instances are detected by
local peak detection of an anchor point and then cropped.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidInferenceModel.centroid_crop">
<span class="sig-name descname"><span class="pre">centroid_crop</span></span><a class="headerlink" href="#sleap.nn.inference.CentroidInferenceModel.centroid_crop" title="Permalink to this definition">#</a></dt>
<dd><p>A centroid cropping layer. This can be either <a class="reference internal" href="#sleap.nn.inference.CentroidCrop" title="sleap.nn.inference.CentroidCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a> or
<a class="reference internal" href="#sleap.nn.inference.CentroidCropGroundTruth" title="sleap.nn.inference.CentroidCropGroundTruth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCropGroundTruth</span></code></a>. This layer takes the full image as input and
outputs a set of centroids and cropped boxes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.CentroidInferenceModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2185-L2209"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.CentroidInferenceModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example</strong>  This may be either a single batch of images as a 4-D tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code>, or a dictionary
containing the image batch in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;images&quot;</span></code> key. If using a ground
truth model for either centroid cropping or instance peaks, the full
example from a <code class="xref py py-obj docutils literal notranslate"><span class="pre">Pipeline</span></code> is required for providing the metadata.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">2)</span></code>: Instance centroids.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances)</span></code>: Instance centroid confidence</p>
<blockquote>
<div><p>values.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">FindInstancePeaks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1944-L2166"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks" title="Permalink to this definition">#</a></dt>
<dd><p>Keras layer that predicts instance peaks from images using a trained model.</p>
<p>This layer encapsulates all of the inference operations required for generating
predictions from a centered instance confidence map model. This includes
preprocessing, model forward pass, peak finding and coordinate adjustment.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that accepts rank-4 images as input and predicts
rank-4 confidence maps as output. This should be a model that is trained on
centered instance confidence maps.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>Float indicating if the images should be resized before being
passed to the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.output_stride">
<span class="sig-name descname"><span class="pre">output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the output
confidence maps relative to the images (after input scaling). This is used
for adjusting the peak coordinates to the image grid. This will be inferred
from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.refinement">
<span class="sig-name descname"><span class="pre">refinement</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, returns the grid-aligned peaks with no refinement. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;integral&quot;</span></code>, peaks will be refined with integral regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>,
peaks will be refined with quarter pixel local gradient offset. This has no
effect if the model has an offset regression head.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.return_confmaps">
<span class="sig-name descname"><span class="pre">return_confmaps</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.return_confmaps" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the confidence maps will be returned together with
the predicted peaks. This will result in slower inference times since the
data must be copied off of the GPU, but is useful for visualizing the raw
output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.confmaps_ind">
<span class="sig-name descname"><span class="pre">confmaps_ind</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.confmaps_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
confidence maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;CenteredInstanceConfmapsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.offsets_ind">
<span class="sig-name descname"><span class="pre">offsets_ind</span></span><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.offsets_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
offset regression maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;OffsetRefinementHead&quot;</span></code> in its name. If the head is not present, the method
specified in the <a class="reference internal" href="#sleap.nn.inference.FindInstancePeaks.refinement" title="sleap.nn.inference.FindInstancePeaks.refinement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">refinement</span></code></a> attribute will be used.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaks.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2027-L2166"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaks.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict confidence maps and infer peak coordinates.</p>
<p>This layer can be chained with a <a class="reference internal" href="#sleap.nn.inference.CentroidCrop" title="sleap.nn.inference.CentroidCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a> layer to create a top-down
inference function from full images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong>  <p>Instance-centered images as a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code> where images are grouped by
sample and may contain a variable number of crops, or a dictionary with
keys:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;crops&quot;</span></code>: Cropped images in either format above.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;crop_offsets&quot;</span></code>: (Optional) Coordinates of the top-left of the crops as</p>
<blockquote>
<div><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y)</span></code> offsets of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">2)</span></code> for adjusting the
predicted peak coordinates. No adjustment is performed if not
provided.</p>
</div></blockquote>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;</span></code>: (Optional) If provided, will be passed through to the</dt><dd><p>output.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;</span></code>: (Optional) If provided, will be passed through to the</dt><dd><p>output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;</span></code>: The predicted peaks for each instance in the batch as a</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">nodes,</span> <span class="pre">2)</span></code>.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;</span></code>: The value of the confidence maps at the predicted</dt><dd><p>peaks for each instance in the batch as a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">nodes)</span></code>.</p>
</dd>
</dl>
<p>If provided (e.g., from an input <a class="reference internal" href="#sleap.nn.inference.CentroidCrop" title="sleap.nn.inference.CentroidCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a> layer), the centroids that
generated the crops will also be included in the keys <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;</span></code>.</p>
<p>If the <a class="reference internal" href="#sleap.nn.inference.FindInstancePeaks.return_confmaps" title="sleap.nn.inference.FindInstancePeaks.return_confmaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">return_confmaps</span></code></a> attribute is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the output will also
contain a key named <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_confmaps&quot;</span></code> containing a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">output_height,</span> <span class="pre">output_width,</span> <span class="pre">nodes)</span></code> containing the
confidence maps predicted by the model.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A dictionary of outputs with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaksGroundTruth">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">FindInstancePeaksGroundTruth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L802-L884"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaksGroundTruth" title="Permalink to this definition">#</a></dt>
<dd><p>Keras layer that simulates a centered instance peaks model.</p>
<p>This layer is useful for testing and evaluating centroid models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.FindInstancePeaksGroundTruth.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example_gt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_output</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L810-L884"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.FindInstancePeaksGroundTruth.call" title="Permalink to this definition">#</a></dt>
<dd><p>Return the ground truth instance peaks given a set of crops.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>example_gt</strong>  <p>Dictionary generated from a labels pipeline with the key:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instances&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances_gt,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code></p>
<blockquote>
<div><p>Axes 1 and 2 are expected to be ragged dimensions.</p>
</div></blockquote>
</p></li>
<li><p><strong>crop_output</strong>  <p>Dictionary containing the output of the instance cropping layer
with keys:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">2)</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids)</span></code></p>
<blockquote>
<div><p>Axis 1 of both keys are expected to be ragged.</p>
</div></blockquote>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A dictionary with the instance peaks for each frame. The peaks are just the
ground truth instances matched to the crop output centroids via greedy
matching of the closest node point to each centroid.</p>
<dl>
<dt>The output will have keys:</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">2)</span></code>: The input centroids.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids)</span></code>: The input centroid</p>
<blockquote>
<div><p>confidence values.</p>
</div></blockquote>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: The matched</dt><dd><p>instances.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_centroids,</span> <span class="pre">n_nodes)</span></code>: Peak</dt><dd><p>confidence values (all 1.0).</p>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">InferenceLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L887-L967"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.InferenceLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Base layer for wrapping a Keras model into a layer with preprocessing.</p>
<p>This layer is useful for wrapping input preprocessing operations that would
otherwise be handled by a separate pipeline.</p>
<p>This layer expects the same input as the model (rank-4 image) and automatically
converts the input to a float if it is in integer form. This can help improve
performance by enabling inference directly on <code class="xref py py-obj docutils literal notranslate"><span class="pre">uint8</span></code> inputs.</p>
<p>The <a class="reference internal" href="#sleap.nn.inference.InferenceLayer.call" title="sleap.nn.inference.InferenceLayer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call()</span></code></a> method can be overloaded to create custom inference routines that
take advantage of the <a class="reference internal" href="#sleap.nn.inference.InferenceLayer.preprocess" title="sleap.nn.inference.InferenceLayer.preprocess"><code class="xref py py-obj docutils literal notranslate"><span class="pre">preprocess()</span></code></a> method.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.InferenceLayer.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that will be called on the input to this layer.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.InferenceLayer.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>If not 1.0, input image will be resized by this factor.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer.pad_to_stride">
<span class="sig-name descname"><span class="pre">pad_to_stride</span></span><a class="headerlink" href="#sleap.nn.inference.InferenceLayer.pad_to_stride" title="Permalink to this definition">#</a></dt>
<dd><p>If not 1, input image will be padded to ensure that it is
divisible by this value (after scaling).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer.ensure_grayscale">
<span class="sig-name descname"><span class="pre">ensure_grayscale</span></span><a class="headerlink" href="#sleap.nn.inference.InferenceLayer.ensure_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, converts inputs to grayscale if not already. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, converts inputs to RGB if not already. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (default), infer
from the shape of the input layer of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer.ensure_float">
<span class="sig-name descname"><span class="pre">ensure_float</span></span><a class="headerlink" href="#sleap.nn.inference.InferenceLayer.ensure_float" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, converts inputs to <code class="xref py py-obj docutils literal notranslate"><span class="pre">float32</span></code> and scales the values to
be between 0 and 1.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L958-L967"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.InferenceLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>Call the model with preprocessed data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong>  Inputs to the model.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output of the model after being called with preprocessing.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceLayer.preprocess">
<span class="sig-name descname"><span class="pre">preprocess</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">imgs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L930-L956"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.InferenceLayer.preprocess" title="Permalink to this definition">#</a></dt>
<dd><p>Apply all preprocessing operations configured for this layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>imgs</strong>  A batch of images as a tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The input tensor after applying preprocessing operations. The tensor will
always be a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.float32</span></code>, which will be adjusted to the range <code class="xref py py-obj docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code> if it
was previously an integer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">InferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L970-L1158"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.InferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>SLEAP inference model base class.</p>
<p>This class wraps the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> class to provide SLEAP-specific inference
utilities such as handling different input data types, preprocessing and variable
output shapes.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceModel.export_model">
<span class="sig-name descname"><span class="pre">export_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signatures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'serving_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_traces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unrag_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1081-L1158"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.InferenceModel.export_model" title="Permalink to this definition">#</a></dt>
<dd><p>Save the frozen graph of a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong>  Path to output directory to store the frozen graph</p></li>
<li><p><strong>signatures</strong>  String defining the input and output types for
computation.</p></li>
<li><p><strong>save_traces</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default) the SavedModel will store the
function traces for each layer</p></li>
<li><p><strong>model_name</strong>  (Optional) Name to give the model. If given, will be
added to the output json file containing meta information about the
model</p></li>
<li><p><strong>tensors</strong>  (Optional) Dictionary describing the predicted tensors (see
sleap.nn.data.utils.describe_tensors as an example)</p></li>
<li><p><strong>unrag_outputs</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), any ragged tensors will be
converted to normal tensors and padded with NaNs</p></li>
</ul>
</dd>
</dl>
<div class="admonition-notes admonition">
<p class="admonition-title">Notes</p>
<p>This function call writes relevant meta data to an <code class="xref py py-obj docutils literal notranslate"><span class="pre">info.json</span></code> file
in the given save_path in addition to the frozen_graph.pb file</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceModel.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">DatasetV2</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline"><span class="pre">Pipeline</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="sleap.io.video.html#sleap.io.video.Video" title="sleap.io.video.Video"><span class="pre">Video</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numpy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">RaggedTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L978-L1034"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.InferenceModel.predict" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances in the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong>  <p>Input data in any form. Possible types:
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code>: Images of shape</p>
<blockquote>
<div><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code></p>
</div></blockquote>
<ul>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code> with key <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;image&quot;</span></code> as a tensor</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> that generates examples in one of the above formats.</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Pipeline</span></code> that generates examples in one of the above formats.</p></li>
<li><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Video</span></code> which will be converted into a pipeline that generates</dt><dd><p>batches of <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_size</span></code> frames.</p>
</dd>
</dl>
</li>
</ul>
</p></li>
<li><p><strong>numpy</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), returned values will be converted to
<a href="#id5"><span class="problematic" id="id6">`</span></a>np.ndarray`s or Python primitives if scalars.</p></li>
<li><p><strong>batch_size</strong>  Batch size to use for inference. No effect if using a dataset or
pipeline as input since those are expected to generate batches.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>The model outputs as a dictionary of (potentially ragged) tensors or numpy
arrays if <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, values of the dictionary may be <a href="#id7"><span class="problematic" id="id8">`</span></a>tf.RaggedTensor`s
with the same length for axis 0 (samples), but variable length axis 1
(instances).</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> and the output contained ragged tensors, they will be
NaN-padded to the bounding shape and an additional key <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;n_valid&quot;</span></code> will be
included to indicate the number of valid elements (before padding) in axis
1 of the tensors.</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.InferenceModel.predict_on_batch">
<span class="sig-name descname"><span class="pre">predict_on_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numpy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">RaggedTensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1036-L1079"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.InferenceModel.predict_on_batch" title="Permalink to this definition">#</a></dt>
<dd><p>Predict a single batch of samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong>  <p>Input data in any form. Possible types:
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code>: Images of shape</p>
<blockquote>
<div><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code></p>
</div></blockquote>
<ul>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code> with key <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;image&quot;</span></code> as a tensor</p></li>
</ul>
</p></li>
<li><p><strong>numpy</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), returned values will be converted to
<a href="#id9"><span class="problematic" id="id10">`</span></a>np.ndarray`s or Python primitives if scalars.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>The model outputs as a dictionary of (potentially ragged) tensors or numpy
arrays if <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, values of the dictionary may be <a href="#id11"><span class="problematic" id="id12">`</span></a>tf.RaggedTensor`s
with the same length for axis 0 (samples), but variable length axis 1
(instances).</p>
<p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> and the output contained ragged tensors, they will be
NaN-padded to the bounding shape and an additional key <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;n_valid&quot;</span></code> will be
included to indicate the number of valid elements (before padding) in axis
1 of the tensors.</p>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">MoveNetInferenceLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4582-L4627"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Inference layer for applying single instance models.</p>
<p>This layer encapsulates all of the inference operations requires for generating
predictions from a single instance confidence map model. This includes
preprocessing, model forward pass, peak finding and coordinate adjustment.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that accepts rank-4 images as input and predicts
rank-4 confidence maps as output. This should be a model that is trained on
single instance confidence maps.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer.model_name">
<span class="sig-name descname"><span class="pre">model_name</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer.model_name" title="Permalink to this definition">#</a></dt>
<dd><p>Variable indicating which model of MoveNet to use, either lightning
or thunder.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>Float indicating if the images should be resized before being
passed to the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer.pad_to_stride">
<span class="sig-name descname"><span class="pre">pad_to_stride</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer.pad_to_stride" title="Permalink to this definition">#</a></dt>
<dd><p>If not 1, input image will be paded to ensure that it is
divisible by this value (after scaling). This should be set to the max
stride of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer.ensure_grayscale">
<span class="sig-name descname"><span class="pre">ensure_grayscale</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer.ensure_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Boolean indicating whether the type of input data is grayscale
or not.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer.ensure_float">
<span class="sig-name descname"><span class="pre">ensure_float</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer.ensure_float" title="Permalink to this definition">#</a></dt>
<dd><p>Boolean indicating whether the type of data is float or not.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ex</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4617-L4627"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>Call the model with preprocessed data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong>  Inputs to the model.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output of the model after being called with preprocessing.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">MoveNetInferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4630-L4654"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>MoveNet prediction model.</p>
<p>This model encapsulates the basic MoveNet approach. The images are passed to a model
which is trained to detect all body parts (17 joints in total).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceModel.inference_layer">
<span class="sig-name descname"><span class="pre">inference_layer</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceModel.inference_layer" title="Permalink to this definition">#</a></dt>
<dd><p>A MoveNet layer. This layer takes as input full images/videos and</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">outputs</span> <span class="pre">the</span> <span class="pre">detected</span> <span class="pre">peaks.</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetInferenceModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4653-L4654"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.MoveNetInferenceModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Calls the model on new inputs and returns the outputs as tensors.</p>
<p>In this case <a class="reference internal" href="#sleap.nn.inference.MoveNetInferenceModel.call" title="sleap.nn.inference.MoveNetInferenceModel.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call()</span></code></a> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<p>Note: This method should not be called directly. It is only meant to be
overridden when subclassing <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>.
To call a model on an input, always use the <code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__()</span></code> method,
i.e. <code class="xref py py-obj docutils literal notranslate"><span class="pre">model(inputs)</span></code>, which relies on the underlying <a class="reference internal" href="#sleap.nn.inference.MoveNetInferenceModel.call" title="sleap.nn.inference.MoveNetInferenceModel.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call()</span></code></a> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong>  Input tensor, or dict/list/tuple of input tensors.</p></li>
<li><p><strong>training</strong>  Boolean or boolean scalar tensor, indicating whether to run
the <code class="xref py py-obj docutils literal notranslate"><span class="pre">Network</span></code> in training mode or inference mode.</p></li>
<li><p><strong>mask</strong>  <p>A mask or list of masks. A mask can be either a boolean tensor or
None (no mask). For more details, check the guide</p>
<blockquote>
<div><p>[here](<a class="reference external" href="https://www.tensorflow.org/guide/keras/masking_and_padding">https://www.tensorflow.org/guide/keras/masking_and_padding</a>).</p>
</div></blockquote>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">MoveNetPredictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inference_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#sleap.nn.inference.MoveNetInferenceModel" title="sleap.nn.inference.MoveNetInferenceModel"><span class="pre">MoveNetInferenceModel</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'lightning'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4658-L4799"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor" title="Permalink to this definition">#</a></dt>
<dd><p>MoveNet predictor.</p>
<p>This high-level class handles initialization, preprocessing and tracking using a
trained MoveNet model.
This should be initialized using the <a class="reference internal" href="#sleap.nn.inference.MoveNetPredictor.from_trained_models" title="sleap.nn.inference.MoveNetPredictor.from_trained_models"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_trained_models()</span></code></a> constructor or the
high-level API (<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.load_model</span></code>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor.inference_model">
<span class="sig-name descname"><span class="pre">inference_model</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor.inference_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.MoveNetInferenceModel" title="sleap.nn.inference.MoveNetInferenceModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.inference.MoveNetInferenceModel</span></code></a> that wraps
a trained <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> to implement preprocessing and peak finding.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#sleap.nn.inference.MoveNetInferenceModel" title="sleap.nn.inference.MoveNetInferenceModel">sleap.nn.inference.MoveNetInferenceModel</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor.pipeline">
<span class="sig-name descname"><span class="pre">pipeline</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor.pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.data.Pipeline</span></code> that loads the data and batches input data.
This will be updated dynamically if new data sources are used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline">sleap.nn.data.pipelines.Pipeline</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor.batch_size" title="Permalink to this definition">#</a></dt>
<dd><p>The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor.model_name">
<span class="sig-name descname"><span class="pre">model_name</span></span><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor.model_name" title="Permalink to this definition">#</a></dt>
<dd><p>Variable indicating which model of MoveNet to use, either lightning
or thunder.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor.from_trained_models">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_trained_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.MoveNetPredictor" title="sleap.nn.inference.MoveNetPredictor"><span class="pre">MoveNetPredictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4710-L4732"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor.from_trained_models" title="Permalink to this definition">#</a></dt>
<dd><p>Create the predictor from a saved model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong>  Variable indicating which model of MoveNet to use, either lightning
or thunder.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a global peak as
valid.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of`MoveNetPredictor` with the models loaded.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.MoveNetPredictor.is_grayscale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_grayscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#sleap.nn.inference.MoveNetPredictor.is_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Return whether the model expects grayscale inputs.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.Predictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">Predictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L159-L589"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.Predictor" title="Permalink to this definition">#</a></dt>
<dd><p>Base interface class for predictors.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.Predictor.export_model">
<span class="sig-name descname"><span class="pre">export_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signatures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'serving_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_traces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unrag_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L533-L589"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.Predictor.export_model" title="Permalink to this definition">#</a></dt>
<dd><p>Export a trained SLEAP model as a frozen graph. Initializes model,
creates a dummy tracing batch and passes it through the model. The
frozen graph is saved along with training meta info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong>  Path to output directory to store the frozen graph</p></li>
<li><p><strong>signatures</strong>  String defining the input and output types for
computation.</p></li>
<li><p><strong>save_traces</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default) the SavedModel will store the
function traces for each layer</p></li>
<li><p><strong>model_name</strong>  (Optional) Name to give the model. If given, will be
added to the output json file containing meta information about the
model</p></li>
<li><p><strong>tensors</strong>  (Optional) Dictionary describing the predicted tensors (see
sleap.nn.data.utils.describe_tensors as an example)</p></li>
<li><p><strong>unrag_outputs</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), any ragged tensors will be
converted to normal tensors and padded with NaNs</p></li>
<li><p><strong>max_instances</strong>  If set, determines the max number of instances that a
multi-instance model returns. This is enforced during centroid
cropping and therefore only compatible with TopDown models.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.Predictor.from_model_paths">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_model_paths</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resize_input_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.Predictor" title="sleap.nn.inference.Predictor"><span class="pre">Predictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L175-L311"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.Predictor.from_model_paths" title="Permalink to this definition">#</a></dt>
<dd><p>Create the appropriate <a class="reference internal" href="#sleap.nn.inference.Predictor" title="sleap.nn.inference.Predictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Predictor</span></code></a> subclass from a list of model paths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_paths</strong>  A single or list of trained model paths. Special cases of
non-SLEAP models include movenet-thunder and movenet-lightning.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a peak as valid.</p></li>
<li><p><strong>integral_refinement</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral
regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter
pixel local gradient offset. This has no effect if the model has an
offset regression head.</p></li>
<li><p><strong>integral_patch_size</strong>  Size of patches to crop around each rough peak for
integral refinement as an integer scalar.</p></li>
<li><p><strong>batch_size</strong>  The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory
usage.</p></li>
<li><p><strong>resize_input_layer</strong>  If True, the the input layer of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Keras.model</span></code> is
resized to (None, None, None, num_color_channels).</p></li>
<li><p><strong>max_instances</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, discard instances beyond this count when
predicting, regardless of whether filtering is done at the tracking
stage. This is useful for preventing extraneous instances from being
created when tracking is not being applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A subclass of <a class="reference internal" href="#sleap.nn.inference.Predictor" title="sleap.nn.inference.Predictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Predictor</span></code></a>.</p>
</dd>
</dl>
<dl class="simple">
<dt>See also: <a class="reference internal" href="#sleap.nn.inference.SingleInstancePredictor" title="sleap.nn.inference.SingleInstancePredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SingleInstancePredictor</span></code></a>, <a class="reference internal" href="#sleap.nn.inference.TopDownPredictor" title="sleap.nn.inference.TopDownPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopDownPredictor</span></code></a>, <a class="reference internal" href="#sleap.nn.inference.BottomUpPredictor" title="sleap.nn.inference.BottomUpPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpPredictor</span></code></a>,</dt><dd><p><a class="reference internal" href="#sleap.nn.inference.MoveNetPredictor" title="sleap.nn.inference.MoveNetPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MoveNetPredictor</span></code></a>, <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassPredictor" title="sleap.nn.inference.TopDownMultiClassPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor</span></code></a>,
<a class="reference internal" href="#sleap.nn.inference.BottomUpMultiClassPredictor" title="sleap.nn.inference.BottomUpMultiClassPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor</span></code></a>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.Predictor.is_grayscale">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_grayscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#sleap.nn.inference.Predictor.is_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Return whether the model expects grayscale inputs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.Predictor.make_pipeline">
<span class="sig-name descname"><span class="pre">make_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Provider</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline"><span class="pre">Pipeline</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L329-L371"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.Predictor.make_pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>Make a data loading pipeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data_provider</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, the pipeline will be created with an instance
of a <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Provider</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The created <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Pipeline</span></code> with batching and prefetching.</p>
</dd>
</dl>
<div class="admonition-notes admonition">
<p class="admonition-title">Notes</p>
<p>This method also updates the class attribute for the pipeline and will be
called automatically when predicting on data from a new source.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.Predictor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Provider</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="sleap.io.dataset.html#sleap.io.dataset.Labels" title="sleap.io.dataset.Labels"><span class="pre">Labels</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="sleap.io.video.html#sleap.io.video.Video" title="sleap.io.video.Video"><span class="pre">Video</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">make_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="sleap.io.dataset.html#sleap.io.dataset.Labels" title="sleap.io.dataset.Labels"><span class="pre">Labels</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L496-L531"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.Predictor.predict" title="Permalink to this definition">#</a></dt>
<dd><p>Run inference on a data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong>  A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Provider</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Labels</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Video</span></code> to
run inference over.</p></li>
<li><p><strong>make_labels</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (the default), returns a <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Labels</span></code> instance with
<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.PredictedInstance`s.</span> <span class="pre">If</span> <span class="pre">`False</span></code>, just return a list of
dictionaries containing the raw arrays returned by the inference model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Labels</span></code> with <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.PredictedInstance`s</span> <span class="pre">if</span> <span class="pre">`make_labels</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>,
otherwise a list of dictionaries containing batches of numpy arrays with the
raw results.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.Predictor.report_period">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">report_period</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#sleap.nn.inference.Predictor.report_period" title="Permalink to this definition">#</a></dt>
<dd><p>Time between progress reports in seconds.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.RateColumn">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">RateColumn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table_column</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Column</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L147-L155"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.RateColumn" title="Permalink to this definition">#</a></dt>
<dd><p>Renders the progress rate.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.RateColumn.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Task</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Text</span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L150-L155"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.RateColumn.render" title="Permalink to this definition">#</a></dt>
<dd><p>Show progress rate.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">SingleInstanceInferenceLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1216-L1367"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Inference layer for applying single instance models.</p>
<p>This layer encapsulates all of the inference operations requires for generating
predictions from a single instance confidence map model. This includes
preprocessing, model forward pass, peak finding and coordinate adjustment.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that accepts rank-4 images as input and predicts
rank-4 confidence maps as output. This should be a model that is trained on
single instance confidence maps.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>Float indicating if the images should be resized before being
passed to the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.pad_to_stride">
<span class="sig-name descname"><span class="pre">pad_to_stride</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.pad_to_stride" title="Permalink to this definition">#</a></dt>
<dd><p>If not 1, input image will be paded to ensure that it is
divisible by this value (after scaling). This should be set to the max
stride of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.output_stride">
<span class="sig-name descname"><span class="pre">output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the output
confidence maps relative to the images (after input scaling). This is used
for adjusting the peak coordinates to the image grid. This will be inferred
from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.refinement">
<span class="sig-name descname"><span class="pre">refinement</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, returns the grid-aligned peaks with no refinement. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;integral&quot;</span></code>, peaks will be refined with integral regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>,
peaks will be refined with quarter pixel local gradient offset. This has no
effect if the model has an offset regression head.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.return_confmaps">
<span class="sig-name descname"><span class="pre">return_confmaps</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.return_confmaps" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the confidence maps will be returned together with
the predicted peaks. This will result in slower inference times since the
data must be copied off of the GPU, but is useful for visualizing the raw
output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.confmaps_ind">
<span class="sig-name descname"><span class="pre">confmaps_ind</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.confmaps_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
confidence maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;SingleInstanceConfmapsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.offsets_ind">
<span class="sig-name descname"><span class="pre">offsets_ind</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.offsets_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
offset regression maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;OffsetRefinementHead&quot;</span></code> in its name. If the head is not present, the method
specified in the <a class="reference internal" href="#sleap.nn.inference.SingleInstanceInferenceLayer.refinement" title="sleap.nn.inference.SingleInstanceInferenceLayer.refinement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">refinement</span></code></a> attribute will be used.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1306-L1367"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instance confidence maps and find peaks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong>  Full frame images as a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code> or a dictionary with key:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;image&quot;</span></code>: Full frame images in the same format as above.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;</span></code>: The predicted peaks of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">1,</span> <span class="pre">nodes,</span> <span class="pre">2)</span></code>.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">The</span> <span class="pre">peak</span> <span class="pre">confidence</span> <span class="pre">values</span> <span class="pre">of</span> <span class="pre">shape</span>
<span class="pre">`(samples,</span> <span class="pre">1,</span> <span class="pre">nodes)</span></code>.</p>
<p>If the <a class="reference internal" href="#sleap.nn.inference.SingleInstanceInferenceLayer.return_confmaps" title="sleap.nn.inference.SingleInstanceInferenceLayer.return_confmaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">return_confmaps</span></code></a> attribute is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the output will also
contain a key named <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;confmaps&quot;</span></code> containing a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">output_height,</span> <span class="pre">output_width,</span> <span class="pre">1)</span></code> containing the confidence maps
predicted by the model.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A dictionary of outputs grouped by sample with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">SingleInstanceInferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1370-L1402"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>Single instance prediction model.</p>
<p>This model encapsulates the basic single instance approach where it is assumed that
there is only one instance in the frame. The images are passed to a peak detector
which is trained to detect all body parts for the instance assuming a single peak
per body part.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceModel.single_instance_layer">
<span class="sig-name descname"><span class="pre">single_instance_layer</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceModel.single_instance_layer" title="Permalink to this definition">#</a></dt>
<dd><p>A single instance instance peak detection layer. This
layer takes as input full images and outputs the detected peaks.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstanceInferenceModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1387-L1402"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.SingleInstanceInferenceModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example</strong>  This may be either a single batch of images as a 4-D tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code>, or a dictionary
containing the image batch in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;images&quot;</span></code> key.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">1,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: Instance skeleton points.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">1,</span> <span class="pre">n_nodes)</span></code>: Confidence</p>
<blockquote>
<div><p>values for the instance skeleton points.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">SingleInstancePredictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">confmap_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">confmap_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#sleap.nn.inference.SingleInstanceInferenceModel" title="sleap.nn.inference.SingleInstanceInferenceModel"><span class="pre">SingleInstanceInferenceModel</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1406-L1622"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor" title="Permalink to this definition">#</a></dt>
<dd><p>Single instance predictor.</p>
<p>This high-level class handles initialization, preprocessing and tracking using a
trained single instance SLEAP model.</p>
<p>This should be initialized using the <a class="reference internal" href="#sleap.nn.inference.SingleInstancePredictor.from_trained_models" title="sleap.nn.inference.SingleInstancePredictor.from_trained_models"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_trained_models()</span></code></a> constructor or the
high-level API (<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.load_model</span></code>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.confmap_config">
<span class="sig-name descname"><span class="pre">confmap_config</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.confmap_config" title="Permalink to this definition">#</a></dt>
<dd><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.config.TrainingJobConfig</span></code> containing the metadata
for the trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig">sleap.nn.config.training_job.TrainingJobConfig</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.confmap_model">
<span class="sig-name descname"><span class="pre">confmap_model</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.confmap_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.model.Model</span></code></a> instance created from the trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model">sleap.nn.model.Model</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.inference_model">
<span class="sig-name descname"><span class="pre">inference_model</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.inference_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.SingleInstanceInferenceModel" title="sleap.nn.inference.SingleInstanceInferenceModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.inference.SingleInstanceInferenceModel</span></code></a> that wraps
a trained <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> to implement preprocessing and peak finding.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#sleap.nn.inference.SingleInstanceInferenceModel" title="sleap.nn.inference.SingleInstanceInferenceModel">sleap.nn.inference.SingleInstanceInferenceModel</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.pipeline">
<span class="sig-name descname"><span class="pre">pipeline</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.data.Pipeline</span></code> that loads the data and batches input data.
This will be updated dynamically if new data sources are used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline">sleap.nn.data.pipelines.Pipeline</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.integral_refinement">
<span class="sig-name descname"><span class="pre">integral_refinement</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.integral_refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral regression.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter pixel local
gradient offset. This has no effect if the model has an offset regression
head.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.batch_size" title="Permalink to this definition">#</a></dt>
<dd><p>The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.export_model">
<span class="sig-name descname"><span class="pre">export_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signatures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'serving_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_traces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unrag_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1602-L1622"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.export_model" title="Permalink to this definition">#</a></dt>
<dd><p>Export a trained SLEAP model as a frozen graph. Initializes model,
creates a dummy tracing batch and passes it through the model. The
frozen graph is saved along with training meta info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong>  Path to output directory to store the frozen graph</p></li>
<li><p><strong>signatures</strong>  String defining the input and output types for
computation.</p></li>
<li><p><strong>save_traces</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default) the SavedModel will store the
function traces for each layer</p></li>
<li><p><strong>model_name</strong>  (Optional) Name to give the model. If given, will be
added to the output json file containing meta information about the
model</p></li>
<li><p><strong>tensors</strong>  (Optional) Dictionary describing the predicted tensors (see
sleap.nn.data.utils.describe_tensors as an example)</p></li>
<li><p><strong>unrag_outputs</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), any ragged tensors will be
converted to normal tensors and padded with NaNs</p></li>
<li><p><strong>max_instances</strong>  If set, determines the max number of instances that a
multi-instance model returns. This is enforced during centroid
cropping and therefore only compatible with TopDown models.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.from_trained_models">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_trained_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resize_input_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.SingleInstancePredictor" title="sleap.nn.inference.SingleInstancePredictor"><span class="pre">SingleInstancePredictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1466-L1519"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.from_trained_models" title="Permalink to this definition">#</a></dt>
<dd><p>Create the predictor from a saved model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong>  Path to a model folder or training job JSON file inside a model
folder. This folder should contain <code class="xref py py-obj docutils literal notranslate"><span class="pre">training_config.json</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> files for a trained model.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a global peak as
valid.</p></li>
<li><p><strong>integral_refinement</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral
regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter
pixel local gradient offset. This has no effect if the model has an
offset regression head.</p></li>
<li><p><strong>integral_patch_size</strong>  Size of patches to crop around each rough peak for
integral refinement as an integer scalar.</p></li>
<li><p><strong>batch_size</strong>  The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory
usage.</p></li>
<li><p><strong>resize_input_layer</strong>  If True, the the input layer of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Keras.model</span></code> is
resized to (None, None, None, num_color_channels).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An instance of`SingleInstancePredictor` with the models loaded.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.SingleInstancePredictor.is_grayscale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_grayscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#sleap.nn.inference.SingleInstancePredictor.is_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Return whether the model expects grayscale inputs.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownInferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">TopDownInferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2212-L2277"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownInferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>Top-down instance prediction model.</p>
<p>This model encapsulates the top-down approach where instances are first detected by
local peak detection of an anchor point and then cropped. These instance-centered
crops are then passed to an instance peak detector which is trained to detect all
remaining body parts for the instance that is centered within the crop.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownInferenceModel.centroid_crop">
<span class="sig-name descname"><span class="pre">centroid_crop</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownInferenceModel.centroid_crop" title="Permalink to this definition">#</a></dt>
<dd><p>A centroid cropping layer. This can be either <a class="reference internal" href="#sleap.nn.inference.CentroidCrop" title="sleap.nn.inference.CentroidCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a> or
<a class="reference internal" href="#sleap.nn.inference.CentroidCropGroundTruth" title="sleap.nn.inference.CentroidCropGroundTruth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCropGroundTruth</span></code></a>. This layer takes the full image as input and
outputs a set of centroids and cropped boxes.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownInferenceModel.instance_peaks">
<span class="sig-name descname"><span class="pre">instance_peaks</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownInferenceModel.instance_peaks" title="Permalink to this definition">#</a></dt>
<dd><p>A instance peak detection layer. This can be either
<a class="reference internal" href="#sleap.nn.inference.FindInstancePeaks" title="sleap.nn.inference.FindInstancePeaks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FindInstancePeaks</span></code></a> or <a class="reference internal" href="#sleap.nn.inference.FindInstancePeaksGroundTruth" title="sleap.nn.inference.FindInstancePeaksGroundTruth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FindInstancePeaksGroundTruth</span></code></a>. This layer takes as
input the output of the centroid cropper and outputs the detected peaks for
the instances within each crop.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownInferenceModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2239-L2277"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownInferenceModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example</strong>  This may be either a single batch of images as a 4-D tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code>, or a dictionary
containing the image batch in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;images&quot;</span></code> key. If using a ground
truth model for either centroid cropping or instance peaks, the full
example from a <code class="xref py py-obj docutils literal notranslate"><span class="pre">Pipeline</span></code> is required for providing the metadata.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">2)</span></code>: Instance centroids.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances)</span></code>: Instance centroid confidence</p>
<blockquote>
<div><p>values.</p>
</div></blockquote>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: Instance skeleton</dt><dd><p>points.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes)</span></code>: Confidence</dt><dd><p>values for the instance skeleton points.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">TopDownMultiClassFindPeaks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3820-L4086"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks" title="Permalink to this definition">#</a></dt>
<dd><p>Keras layer that predicts and classifies peaks from images using a trained model.</p>
<p>This layer encapsulates all of the inference operations required for generating
predictions from a centered instance confidence map and multi-class model. This
includes preprocessing, model forward pass, peak finding, coordinate adjustment, and
classification.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.keras_model">
<span class="sig-name descname"><span class="pre">keras_model</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.keras_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> that accepts rank-4 images as input and predicts
rank-4 confidence maps as output. This should be a model that is trained on
centered instance confidence maps and classification.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.input_scale">
<span class="sig-name descname"><span class="pre">input_scale</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.input_scale" title="Permalink to this definition">#</a></dt>
<dd><p>Float indicating if the images should be resized before being
passed to the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.output_stride">
<span class="sig-name descname"><span class="pre">output_stride</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Output stride of the model, denoting the scale of the output
confidence maps relative to the images (after input scaling). This is used
for adjusting the peak coordinates to the image grid. This will be inferred
from the model shapes if not provided.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a global peak as valid.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.refinement">
<span class="sig-name descname"><span class="pre">refinement</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, returns the grid-aligned peaks with no refinement. If
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;integral&quot;</span></code>, peaks will be refined with integral regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>,
peaks will be refined with quarter pixel local gradient offset. This has no
effect if the model has an offset regression head.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.return_confmaps">
<span class="sig-name descname"><span class="pre">return_confmaps</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_confmaps" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the confidence maps will be returned together with
the predicted peaks. This will result in slower inference times since the
data must be copied off of the GPU, but is useful for visualizing the raw
output of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.return_class_vectors">
<span class="sig-name descname"><span class="pre">return_class_vectors</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_class_vectors" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the classification probabilities will be
returned together with the predicted peaks. This will not line up with the
grouped instances, for which the associtated class probabilities will always
be returned in <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_scores&quot;</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.confmaps_ind">
<span class="sig-name descname"><span class="pre">confmaps_ind</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.confmaps_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
confidence maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;CenteredInstanceConfmapsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.offsets_ind">
<span class="sig-name descname"><span class="pre">offsets_ind</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.offsets_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to
offset regression maps. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;OffsetRefinementHead&quot;</span></code> in its name. If the head is not present, the method
specified in the <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.refinement" title="sleap.nn.inference.TopDownMultiClassFindPeaks.refinement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">refinement</span></code></a> attribute will be used.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.class_vectors_ind">
<span class="sig-name descname"><span class="pre">class_vectors_ind</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.class_vectors_ind" title="Permalink to this definition">#</a></dt>
<dd><p>Index of the output tensor of the model corresponding to the
classification vectors. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> (the default), this will be detected
automatically by searching for the first tensor that contains
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;ClassVectorsHead&quot;</span></code> in its name.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.optimal_grouping">
<span class="sig-name descname"><span class="pre">optimal_grouping</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.optimal_grouping" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (the default), group peaks from classification
probabilities. If saving a frozen graph of the model, this will be
overridden to <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassFindPeaks.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L3928-L4086"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict confidence maps and infer peak coordinates.</p>
<p>This layer can be chained with a <a class="reference internal" href="#sleap.nn.inference.CentroidCrop" title="sleap.nn.inference.CentroidCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a> layer to create a top-down
inference function from full images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong>  <p>Instance-centered images as a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code> where images are grouped by
sample and may contain a variable number of crops, or a dictionary with
keys:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;crops&quot;</span></code>: Cropped images in either format above.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;crop_offsets&quot;</span></code>: (Optional) Coordinates of the top-left of the crops as</p>
<blockquote>
<div><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y)</span></code> offsets of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">2)</span></code> for adjusting the
predicted peak coordinates. No adjustment is performed if not
provided.</p>
</div></blockquote>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;</span></code>: (Optional) If provided, will be passed through to the</dt><dd><p>output.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;</span></code>: (Optional) If provided, will be passed through to the</dt><dd><p>output.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;</span></code>: The predicted peaks for each instance in the batch as a</dt><dd><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">n_classes,</span> <span class="pre">nodes,</span> <span class="pre">2)</span></code>. Instances will
be ordered by class and will be filled with <code class="xref py py-obj docutils literal notranslate"><span class="pre">NaN</span></code> where not found.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;</span></code>: The value of the confidence maps at the predicted</dt><dd><p>peaks for each instance in the batch as a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">n_classes,</span> <span class="pre">nodes)</span></code>.</p>
</dd>
</dl>
<p>If provided (e.g., from an input <a class="reference internal" href="#sleap.nn.inference.CentroidCrop" title="sleap.nn.inference.CentroidCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a> layer), the centroids that
generated the crops will also be included in the keys <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;</span></code>.</p>
<p>If the <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_confmaps" title="sleap.nn.inference.TopDownMultiClassFindPeaks.return_confmaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">return_confmaps</span></code></a> attribute is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the output will also
contain a key named <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_confmaps&quot;</span></code> containing a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.RaggedTensor</span></code> of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(samples,</span> <span class="pre">?,</span> <span class="pre">output_height,</span> <span class="pre">output_width,</span> <span class="pre">nodes)</span></code> containing the
confidence maps predicted by the model.</p>
<p>If the <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_class_vectors" title="sleap.nn.inference.TopDownMultiClassFindPeaks.return_class_vectors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">return_class_vectors</span></code></a> attribute is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, the output will also
contain a key named <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;class_vectors&quot;</span></code> containing the full classification
probabilities for all crops.</p>
<p>If the <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.optimal_grouping" title="sleap.nn.inference.TopDownMultiClassFindPeaks.optimal_grouping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimal_grouping</span></code></a> attribute is set to <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks are
grouped from classification properties. This is overridden to False
if exporting a frozen graph to allow for tracing. Note: If set to False
this will change the output dict keys and shapes.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A dictionary of outputs with keys</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassInferenceModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">TopDownMultiClassInferenceModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4089-L4159"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassInferenceModel" title="Permalink to this definition">#</a></dt>
<dd><p>Top-down instance prediction model.</p>
<p>This model encapsulates the top-down approach where instances are first detected by
local peak detection of an anchor point and then cropped. These instance-centered
crops are then passed to an instance peak detector which is trained to detect all
remaining body parts for the instance that is centered within the crop.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassInferenceModel.centroid_crop">
<span class="sig-name descname"><span class="pre">centroid_crop</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.centroid_crop" title="Permalink to this definition">#</a></dt>
<dd><p>A centroid cropping layer. This can be either <a class="reference internal" href="#sleap.nn.inference.CentroidCrop" title="sleap.nn.inference.CentroidCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a> or
<a class="reference internal" href="#sleap.nn.inference.CentroidCropGroundTruth" title="sleap.nn.inference.CentroidCropGroundTruth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CentroidCropGroundTruth</span></code></a>. This layer takes the full image as input and
outputs a set of centroids and cropped boxes.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassInferenceModel.instance_peaks">
<span class="sig-name descname"><span class="pre">instance_peaks</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.instance_peaks" title="Permalink to this definition">#</a></dt>
<dd><p>A instance peak detection and classification layer, an instance
of <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassFindPeaks" title="sleap.nn.inference.TopDownMultiClassFindPeaks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks</span></code></a>. This layer takes as input the output of the
centroid cropper and outputs the detected peaks and classes for the
instances within each crop.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassInferenceModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4116-L4144"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Predict instances for one batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example</strong>  This may be either a single batch of images as a 4-D tensor of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">height,</span> <span class="pre">width,</span> <span class="pre">channels)</span></code>, or a dictionary
containing the image batch in the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;images&quot;</span></code> key. If using a ground
truth model for either centroid cropping or instance peaks, the full
example from a <code class="xref py py-obj docutils literal notranslate"><span class="pre">Pipeline</span></code> is required for providing the metadata.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroids&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">2)</span></code>: Instance centroids.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;centroid_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances)</span></code>: Instance centroid confidence</p>
<blockquote>
<div><p>values.</p>
</div></blockquote>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peaks&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes,</span> <span class="pre">2)</span></code>: Instance skeleton</dt><dd><p>points.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;instance_peak_vals&quot;:</span> <span class="pre">(batch_size,</span> <span class="pre">n_instances,</span> <span class="pre">n_nodes)</span></code>: Confidence</dt><dd><p>values for the instance skeleton points.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The predicted instances as a dictionary of tensors with keys</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassInferenceModel.export_model">
<span class="sig-name descname"><span class="pre">export_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signatures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'serving_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_traces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unrag_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4146-L4159"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.export_model" title="Permalink to this definition">#</a></dt>
<dd><p>Save the frozen graph of a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong>  Path to output directory to store the frozen graph</p></li>
<li><p><strong>signatures</strong>  String defining the input and output types for
computation.</p></li>
<li><p><strong>save_traces</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default) the SavedModel will store the
function traces for each layer</p></li>
<li><p><strong>model_name</strong>  (Optional) Name to give the model. If given, will be
added to the output json file containing meta information about the
model</p></li>
<li><p><strong>tensors</strong>  (Optional) Dictionary describing the predicted tensors (see
sleap.nn.data.utils.describe_tensors as an example)</p></li>
<li><p><strong>unrag_outputs</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), any ragged tensors will be
converted to normal tensors and padded with NaNs</p></li>
</ul>
</dd>
</dl>
<div class="admonition-notes admonition">
<p class="admonition-title">Notes</p>
<p>This function call writes relevant meta data to an <code class="xref py py-obj docutils literal notranslate"><span class="pre">info.json</span></code> file
in the given save_path in addition to the frozen_graph.pb file</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">TopDownMultiClassPredictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">centroid_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centroid_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confmap_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confmap_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassInferenceModel" title="sleap.nn.inference.TopDownMultiClassInferenceModel"><span class="pre">TopDownMultiClassInferenceModel</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.instance.html#sleap.instance.Track" title="sleap.instance.Track"><span class="pre">Track</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4163-L4542"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor" title="Permalink to this definition">#</a></dt>
<dd><p>Top-down multi-instance predictor with classification.</p>
<p>This high-level class handles initialization, preprocessing and tracking using a
trained top-down multi-instance classification SLEAP model.</p>
<p>This should be initialized using the <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassPredictor.from_trained_models" title="sleap.nn.inference.TopDownMultiClassPredictor.from_trained_models"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_trained_models()</span></code></a> constructor or the
high-level API (<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.load_model</span></code>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.centroid_config">
<span class="sig-name descname"><span class="pre">centroid_config</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.centroid_config" title="Permalink to this definition">#</a></dt>
<dd><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.config.TrainingJobConfig</span></code> containing the metadata
for the trained centroid model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth centroids will be
used if available from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig">sleap.nn.config.training_job.TrainingJobConfig</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.centroid_model">
<span class="sig-name descname"><span class="pre">centroid_model</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.centroid_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.model.Model</span></code></a> instance created from the trained
centroid model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth centroids will be used if available
from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model">sleap.nn.model.Model</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.confmap_config">
<span class="sig-name descname"><span class="pre">confmap_config</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.confmap_config" title="Permalink to this definition">#</a></dt>
<dd><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.config.TrainingJobConfig</span></code> containing the metadata
for the trained centered instance model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth instances
will be used if available from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig">sleap.nn.config.training_job.TrainingJobConfig</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.confmap_model">
<span class="sig-name descname"><span class="pre">confmap_model</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.confmap_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.model.Model</span></code></a> instance created from the trained
centered-instance model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth instances will be used if
available from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model">sleap.nn.model.Model</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.inference_model">
<span class="sig-name descname"><span class="pre">inference_model</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.inference_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassInferenceModel" title="sleap.nn.inference.TopDownMultiClassInferenceModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel</span></code></a> that wraps a trained
<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> to implement preprocessing, centroid detection, cropping,
peak finding and classification.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassInferenceModel" title="sleap.nn.inference.TopDownMultiClassInferenceModel">sleap.nn.inference.TopDownMultiClassInferenceModel</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.pipeline">
<span class="sig-name descname"><span class="pre">pipeline</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.data.Pipeline</span></code> that loads the data and batches input data.
This will be updated dynamically if new data sources are used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline">sleap.nn.data.pipelines.Pipeline</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.tracker">
<span class="sig-name descname"><span class="pre">tracker</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.tracker" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.tracking.html#sleap.nn.tracking.Tracker" title="sleap.nn.tracking.Tracker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.tracking.Tracker</span></code></a> that will be called to associate
detections over time. Predicted instances will not be assigned to tracks if
if this is <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.tracking.html#sleap.nn.tracking.Tracker" title="sleap.nn.tracking.Tracker">sleap.nn.tracking.Tracker</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.batch_size" title="Permalink to this definition">#</a></dt>
<dd><p>The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a local peak as valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.integral_refinement">
<span class="sig-name descname"><span class="pre">integral_refinement</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.integral_refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral regression.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter pixel local
gradient offset. This has no effect if the model has an offset regression
head.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.tracks">
<span class="sig-name descname"><span class="pre">tracks</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.tracks" title="Permalink to this definition">#</a></dt>
<dd><p>If provided, instances will be created using these track instances. If
not, instances will be assigned tracks from the provider if possible.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[List[<a class="reference internal" href="sleap.instance.html#sleap.instance.Track" title="sleap.instance.Track">sleap.instance.Track</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.export_model">
<span class="sig-name descname"><span class="pre">export_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signatures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'serving_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_traces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unrag_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4515-L4542"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.export_model" title="Permalink to this definition">#</a></dt>
<dd><p>Export a trained SLEAP model as a frozen graph. Initializes model,
creates a dummy tracing batch and passes it through the model. The
frozen graph is saved along with training meta info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong>  Path to output directory to store the frozen graph</p></li>
<li><p><strong>signatures</strong>  String defining the input and output types for
computation.</p></li>
<li><p><strong>save_traces</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default) the SavedModel will store the
function traces for each layer</p></li>
<li><p><strong>model_name</strong>  (Optional) Name to give the model. If given, will be
added to the output json file containing meta information about the
model</p></li>
<li><p><strong>tensors</strong>  (Optional) Dictionary describing the predicted tensors (see
sleap.nn.data.utils.describe_tensors as an example)</p></li>
<li><p><strong>unrag_outputs</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), any ragged tensors will be
converted to normal tensors and padded with NaNs</p></li>
<li><p><strong>max_instances</strong>  If set, determines the max number of instances that a
multi-instance model returns. This is enforced during centroid
cropping and therefore only compatible with TopDown models.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.from_trained_models">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_trained_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">centroid_model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confmap_model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resize_input_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassPredictor" title="sleap.nn.inference.TopDownMultiClassPredictor"><span class="pre">TopDownMultiClassPredictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4262-L4350"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.from_trained_models" title="Permalink to this definition">#</a></dt>
<dd><p>Create predictor from saved models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>centroid_model_path</strong>  Path to a centroid model folder or training job JSON
file inside a model folder. This folder should contain
<code class="xref py py-obj docutils literal notranslate"><span class="pre">training_config.json</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> files for a trained model.</p></li>
<li><p><strong>confmap_model_path</strong>  Path to a centered instance model folder or training job
JSON file inside a model folder. This folder should contain
<code class="xref py py-obj docutils literal notranslate"><span class="pre">training_config.json</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> files for a trained model.</p></li>
<li><p><strong>batch_size</strong>  The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory
usage.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a local peak as
valid.</p></li>
<li><p><strong>integral_refinement</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral
regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter
pixel local gradient offset. This has no effect if the model has an
offset regression head.</p></li>
<li><p><strong>integral_patch_size</strong>  Size of patches to crop around each rough peak for
integral refinement as an integer scalar.</p></li>
<li><p><strong>resize_input_layer</strong>  If True, the the input layer of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Keras.model</span></code> is
resized to (None, None, None, num_color_channels).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>An instance of <a class="reference internal" href="#sleap.nn.inference.TopDownMultiClassPredictor" title="sleap.nn.inference.TopDownMultiClassPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor</span></code></a> with the loaded models.</p>
<p>One of the two models can be left as <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> to perform inference with ground
truth data. This will only work with <code class="xref py py-obj docutils literal notranslate"><span class="pre">LabelsReader</span></code> as the provider.</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.is_grayscale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_grayscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.is_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Return whether the model expects grayscale inputs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownMultiClassPredictor.make_pipeline">
<span class="sig-name descname"><span class="pre">make_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Provider</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline"><span class="pre">Pipeline</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4370-L4404"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownMultiClassPredictor.make_pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>Make a data loading pipeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data_provider</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, the pipeline will be created with an instance
of a <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Provider</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The created <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Pipeline</span></code> with batching and prefetching.</p>
</dd>
</dl>
<div class="admonition-notes admonition">
<p class="admonition-title">Notes</p>
<p>This method also updates the class attribute for the pipeline and will be
called automatically when predicting on data from a new source.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">TopDownPredictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">centroid_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">centroid_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confmap_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confmap_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#sleap.nn.inference.TopDownInferenceModel" title="sleap.nn.inference.TopDownInferenceModel"><span class="pre">TopDownInferenceModel</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2281-L2692"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor" title="Permalink to this definition">#</a></dt>
<dd><p>Top-down multi-instance predictor.</p>
<p>This high-level class handles initialization, preprocessing and tracking using a
trained top-down multi-instance SLEAP model.</p>
<p>This should be initialized using the <a class="reference internal" href="#sleap.nn.inference.TopDownPredictor.from_trained_models" title="sleap.nn.inference.TopDownPredictor.from_trained_models"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_trained_models()</span></code></a> constructor or the
high-level API (<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.load_model</span></code>).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.centroid_config">
<span class="sig-name descname"><span class="pre">centroid_config</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.centroid_config" title="Permalink to this definition">#</a></dt>
<dd><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.config.TrainingJobConfig</span></code> containing the metadata
for the trained centroid model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth centroids will be
used if available from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig">sleap.nn.config.training_job.TrainingJobConfig</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.centroid_model">
<span class="sig-name descname"><span class="pre">centroid_model</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.centroid_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.model.Model</span></code></a> instance created from the trained
centroid model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth centroids will be used if available
from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model">sleap.nn.model.Model</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.confmap_config">
<span class="sig-name descname"><span class="pre">confmap_config</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.confmap_config" title="Permalink to this definition">#</a></dt>
<dd><p>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.config.TrainingJobConfig</span></code> containing the metadata
for the trained centered instance model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth instances
will be used if available from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig">sleap.nn.config.training_job.TrainingJobConfig</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.confmap_model">
<span class="sig-name descname"><span class="pre">confmap_model</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.confmap_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.model.Model</span></code></a> instance created from the trained
centered-instance model. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, ground truth instances will be used if
available from the data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model">sleap.nn.model.Model</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.inference_model">
<span class="sig-name descname"><span class="pre">inference_model</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.inference_model" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="#sleap.nn.inference.TopDownInferenceModel" title="sleap.nn.inference.TopDownInferenceModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.inference.TopDownInferenceModel</span></code></a> that wraps a
trained <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> to implement preprocessing, centroid detection,
cropping and peak finding.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#sleap.nn.inference.TopDownInferenceModel" title="sleap.nn.inference.TopDownInferenceModel">sleap.nn.inference.TopDownInferenceModel</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.pipeline">
<span class="sig-name descname"><span class="pre">pipeline</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.data.Pipeline</span></code> that loads the data and batches input data.
This will be updated dynamically if new data sources are used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline">sleap.nn.data.pipelines.Pipeline</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.tracker">
<span class="sig-name descname"><span class="pre">tracker</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.tracker" title="Permalink to this definition">#</a></dt>
<dd><p>A <a class="reference internal" href="sleap.nn.tracking.html#sleap.nn.tracking.Tracker" title="sleap.nn.tracking.Tracker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.nn.tracking.Tracker</span></code></a> that will be called to associate
detections over time. Predicted instances will not be assigned to tracks if
if this is <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="sleap.nn.tracking.html#sleap.nn.tracking.Tracker" title="sleap.nn.tracking.Tracker">sleap.nn.tracking.Tracker</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.batch_size" title="Permalink to this definition">#</a></dt>
<dd><p>The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory usage.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.peak_threshold">
<span class="sig-name descname"><span class="pre">peak_threshold</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.peak_threshold" title="Permalink to this definition">#</a></dt>
<dd><p>Minimum confidence map value to consider a local peak as valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.integral_refinement">
<span class="sig-name descname"><span class="pre">integral_refinement</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.integral_refinement" title="Permalink to this definition">#</a></dt>
<dd><p>If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral regression.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter pixel local
gradient offset. This has no effect if the model has an offset regression
head.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.integral_patch_size">
<span class="sig-name descname"><span class="pre">integral_patch_size</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.integral_patch_size" title="Permalink to this definition">#</a></dt>
<dd><p>Size of patches to crop around each rough peak for integral
refinement as an integer scalar.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.max_instances">
<span class="sig-name descname"><span class="pre">max_instances</span></span><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.max_instances" title="Permalink to this definition">#</a></dt>
<dd><p>If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, discard instances beyond this count when
predicting, regardless of whether filtering is done at the tracking stage.
This is useful for preventing extraneous instances from being created when
tracking is not being applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.export_model">
<span class="sig-name descname"><span class="pre">export_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signatures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'serving_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_traces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unrag_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2665-L2692"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.export_model" title="Permalink to this definition">#</a></dt>
<dd><p>Export a trained SLEAP model as a frozen graph. Initializes model,
creates a dummy tracing batch and passes it through the model. The
frozen graph is saved along with training meta info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_path</strong>  Path to output directory to store the frozen graph</p></li>
<li><p><strong>signatures</strong>  String defining the input and output types for
computation.</p></li>
<li><p><strong>save_traces</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default) the SavedModel will store the
function traces for each layer</p></li>
<li><p><strong>model_name</strong>  (Optional) Name to give the model. If given, will be
added to the output json file containing meta information about the
model</p></li>
<li><p><strong>tensors</strong>  (Optional) Dictionary describing the predicted tensors (see
sleap.nn.data.utils.describe_tensors as an example)</p></li>
<li><p><strong>unrag_outputs</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), any ragged tensors will be
converted to normal tensors and padded with NaNs</p></li>
<li><p><strong>max_instances</strong>  If set, determines the max number of instances that a
multi-instance model returns. This is enforced during centroid
cropping and therefore only compatible with TopDown models.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.from_trained_models">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_trained_models</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">centroid_model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confmap_model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">integral_patch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resize_input_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.TopDownPredictor" title="sleap.nn.inference.TopDownPredictor"><span class="pre">TopDownPredictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2392-L2488"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.from_trained_models" title="Permalink to this definition">#</a></dt>
<dd><p>Create predictor from saved models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>centroid_model_path</strong>  Path to a centroid model folder or training job JSON
file inside a model folder. This folder should contain
<code class="xref py py-obj docutils literal notranslate"><span class="pre">training_config.json</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> files for a trained model.</p></li>
<li><p><strong>confmap_model_path</strong>  Path to a centered instance model folder or training job
JSON file inside a model folder. This folder should contain
<code class="xref py py-obj docutils literal notranslate"><span class="pre">training_config.json</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> files for a trained model.</p></li>
<li><p><strong>batch_size</strong>  The default batch size to use when loading data for inference.
Higher values increase inference speed at the cost of higher memory
usage.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a local peak as
valid.</p></li>
<li><p><strong>integral_refinement</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>, peaks will be refined with integral
regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter
pixel local gradient offset. This has no effect if the model has an
offset regression head.</p></li>
<li><p><strong>integral_patch_size</strong>  Size of patches to crop around each rough peak for
integral refinement as an integer scalar.</p></li>
<li><p><strong>resize_input_layer</strong>  If True, the the input layer of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Keras.model</span></code> is
resized to (None, None, None, num_color_channels).</p></li>
<li><p><strong>max_instances</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, discard instances beyond this count when
predicting, regardless of whether filtering is done at the tracking
stage. This is useful for preventing extraneous instances from being
created when tracking is not being applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>An instance of <a class="reference internal" href="#sleap.nn.inference.TopDownPredictor" title="sleap.nn.inference.TopDownPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopDownPredictor</span></code></a> with the loaded models.</p>
<p>One of the two models can be left as <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> to perform inference with ground
truth data. This will only work with <code class="xref py py-obj docutils literal notranslate"><span class="pre">LabelsReader</span></code> as the provider.</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.is_grayscale">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_grayscale</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.is_grayscale" title="Permalink to this definition">#</a></dt>
<dd><p>Return whether the model expects grayscale inputs.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.TopDownPredictor.make_pipeline">
<span class="sig-name descname"><span class="pre">make_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Provider</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="sleap.nn.data.pipelines.html#sleap.nn.data.pipelines.Pipeline" title="sleap.nn.data.pipelines.Pipeline"><span class="pre">Pipeline</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L2500-L2546"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.TopDownPredictor.make_pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>Make a data loading pipeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data_provider</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, the pipeline will be created with an instance
of a <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Provider</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The created <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Pipeline</span></code> with batching and prefetching.</p>
</dd>
</dl>
<div class="admonition-notes admonition">
<p class="admonition-title">Notes</p>
<p>This method also updates the class attribute for the pipeline and will be
called automatically when predicting on data from a new source.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sleap.nn.inference.VisualPredictor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">VisualPredictor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.config.training_job.html#sleap.nn.config.training_job.TrainingJobConfig" title="sleap.nn.config.training_job.TrainingJobConfig"><span class="pre">TrainingJobConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="sleap.nn.model.html#sleap.nn.model.Model" title="sleap.nn.model.Model"><span class="pre">Model</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbosity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_paths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">_Nothing.NOTHING</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L594-L720"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.VisualPredictor" title="Permalink to this definition">#</a></dt>
<dd><p>Predictor class for generating the visual output of model.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.VisualPredictor.make_pipeline">
<span class="sig-name descname"><span class="pre">make_pipeline</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L650-L668"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.VisualPredictor.make_pipeline" title="Permalink to this definition">#</a></dt>
<dd><p>Make a data loading pipeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data_provider</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, the pipeline will be created with an instance
of a <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Provider</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The created <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Pipeline</span></code> with batching and prefetching.</p>
</dd>
</dl>
<div class="admonition-notes admonition">
<p class="admonition-title">Notes</p>
<p>This method also updates the class attribute for the pipeline and will be
called automatically when predicting on data from a new source.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.VisualPredictor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Provider</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L716-L720"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.VisualPredictor.predict" title="Permalink to this definition">#</a></dt>
<dd><p>Run inference on a data source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong>  A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.pipelines.Provider</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Labels</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Video</span></code> to
run inference over.</p></li>
<li><p><strong>make_labels</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (the default), returns a <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Labels</span></code> instance with
<code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.PredictedInstance`s.</span> <span class="pre">If</span> <span class="pre">`False</span></code>, just return a list of
dictionaries containing the raw arrays returned by the inference model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.Labels</span></code> with <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap.PredictedInstance`s</span> <span class="pre">if</span> <span class="pre">`make_labels</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code>,
otherwise a list of dictionaries containing batches of numpy arrays with the
raw results.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sleap.nn.inference.VisualPredictor.safely_generate">
<span class="sig-name descname"><span class="pre">safely_generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DatasetV2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L670-L704"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.VisualPredictor.safely_generate" title="Permalink to this definition">#</a></dt>
<dd><p>Yields examples from dataset, catching and logging exceptions.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.export_cli">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">export_cli</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4987-L5002"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.export_cli" title="Permalink to this definition">#</a></dt>
<dd><p>CLI for sleap-export.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.export_model">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">export_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'exported_model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signatures</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'serving_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_traces</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unrag_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4944-L4984"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.export_model" title="Permalink to this definition">#</a></dt>
<dd><p>High level export of a trained SLEAP model as a frozen graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong>  Path to model or list of path to models that were trained by SLEAP.
These should be the directories that contain <code class="xref py py-obj docutils literal notranslate"><span class="pre">training_job.json</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code>.</p></li>
<li><p><strong>save_path</strong>  Path to output directory to store the frozen graph.</p></li>
<li><p><strong>signatures</strong>  String defining the input and output types for computation.</p></li>
<li><p><strong>save_traces</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default) the SavedModel will store the function traces
for each layer.</p></li>
<li><p><strong>model_name</strong>  (Optional) Name to give the model. If given, will be added to the
output json file containing meta information about the model.</p></li>
<li><p><strong>tensors</strong>  (Optional) Dictionary describing the predicted tensors (see
sleap.nn.data.utils.describe_tensors as an example).</p></li>
<li><p><strong>unrag_outputs</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (default), any ragged tensors will be
converted to normal tensors and padded with NaNs</p></li>
<li><p><strong>max_instances</strong>  If set, determines the max number of instances that a
multi-instance model returns. This is enforced during centroid
cropping and therefore only compatible with TopDown models.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.find_head">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">find_head</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1191-L1213"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.find_head" title="Permalink to this definition">#</a></dt>
<dd><p>Return the index of a head in a models outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong>  A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> trained by SLEAP.</p></li>
<li><p><strong>name</strong>  A string that is contained in the model output tensor name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The index of the first output with a matched name or <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> if none were found.</p>
</dd>
</dl>
<div class="admonition-notes admonition">
<p class="admonition-title">Notes</p>
<p>SLEAP model heads are named:
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;SingleInstanceConfmapsHead&quot;</span></code>
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;CentroidConfmapsHead&quot;</span></code>
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;CenteredInstanceConfmapsHead&quot;</span></code>
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;MultiInstanceConfmapsHead&quot;</span></code>
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;PartAffinityFieldsHead&quot;</span></code>
- <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;OffsetRefinementHead&quot;</span></code></p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.get_keras_model_path">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">get_keras_model_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L132-L144"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.get_keras_model_path" title="Permalink to this definition">#</a></dt>
<dd><p>Utility method for finding the path to a saved Keras model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong>  Path to a model run folder or job file.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Path to <code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code> in the run folder.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.get_model_output_stride">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">get_model_output_stride</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_ind</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L1161-L1188"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.get_model_output_stride" title="Permalink to this definition">#</a></dt>
<dd><p>Return the stride (1/scale) of the model outputs relative to the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong>  A <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>.</p></li>
<li><p><strong>input_ind</strong>  The index of the input to use as reference. Defaults to 0, indicating
the first input for multi-output models.</p></li>
<li><p><strong>output_ind</strong>  The index of the output to compute the stride for. Defaults to -1,
indicating the last output for multi-output models.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>The output stride of the model computed as the integer ratio of the inputs
height relative to the outputs height, e.g., for a single input/output model:</p>
<blockquote>
<div><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">model.input.shape[1]</span> <span class="pre">//</span> <span class="pre">model.output.shape[1]</span></code></p>
</div></blockquote>
<p>Raises a warning if the shapes do not divide evenly.</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.load_model">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peak_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">refinement</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'integral'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracker</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracker_window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracker_max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">disable_gpu_preallocation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_reporting</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rich'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resize_input_layer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_instances</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#sleap.nn.inference.Predictor" title="sleap.nn.inference.Predictor"><span class="pre">Predictor</span></a></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4802-L4941"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.load_model" title="Permalink to this definition">#</a></dt>
<dd><p>Load a trained SLEAP model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong>  Path to model or list of path to models that were trained by SLEAP.
These should be the directories that contain <code class="xref py py-obj docutils literal notranslate"><span class="pre">training_job.json</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">best_model.h5</span></code>. Special cases of non-SLEAP models include movenet-thunder
and movenet-lightning.</p></li>
<li><p><strong>batch_size</strong>  Number of frames to predict at a time. Larger values result in
faster inference speeds, but require more memory.</p></li>
<li><p><strong>peak_threshold</strong>  Minimum confidence map value to consider a peak as valid.</p></li>
<li><p><strong>refinement</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;integral&quot;</span></code>, peak locations will be refined with integral
regression. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;local&quot;</span></code>, peaks will be refined with quarter pixel local
gradient offset. This has no effect if the model has an offset regression
head.</p></li>
<li><p><strong>tracker</strong>  Name of the tracker to use with the inference model. Must be one of
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;simple&quot;</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;flow&quot;</span></code>. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, no identity tracking across frames will
be performed.</p></li>
<li><p><strong>tracker_window</strong>  Number of frames of history to use when tracking. No effect when
<code class="xref py py-obj docutils literal notranslate"><span class="pre">tracker</span></code> is <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>tracker_max_instances</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, create at most this many tracks.</p></li>
<li><p><strong>disable_gpu_preallocation</strong>  If <code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code> (the default), initialize the GPU and
disable preallocation of memory. This is necessary to prevent freezing on
some systems with low GPU memory and has negligible impact on performance.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code>, no GPU initialization is performed. No effect if running in
CPU-only mode.</p></li>
<li><p><strong>progress_reporting</strong>  Mode of inference progress reporting. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;rich&quot;</span></code> (the
default), an updating progress bar is displayed in the console or notebook.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;json&quot;</span></code>, a JSON-serialized message is printed out which can be captured
for programmatic progress monitoring. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>, nothing is displayed
during inference  this is recommended when running on clusters or headless
machines where the output is captured to a log file.</p></li>
<li><p><strong>resize_input_layer</strong>  If True, the the input layer of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Keras.model</span></code> is
resized to (None, None, None, num_color_channels).</p></li>
<li><p><strong>max_instances</strong>  If not <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code>, discard instances beyond this count when
predicting, regardless of whether filtering is done at the tracking stage.
This is useful for preventing extraneous instances from being created when
tracking is not being applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>An instance of a <a class="reference internal" href="#sleap.nn.inference.Predictor" title="sleap.nn.inference.Predictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Predictor</span></code></a> based on which model type was detected.</p>
<p>If this is a top-down model, paths to the centroids model as well as the
centered instance model must be provided. A <a class="reference internal" href="#sleap.nn.inference.TopDownPredictor" title="sleap.nn.inference.TopDownPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TopDownPredictor</span></code></a> instance will be
returned.</p>
<p>If this is a bottom-up model, a <a class="reference internal" href="#sleap.nn.inference.BottomUpPredictor" title="sleap.nn.inference.BottomUpPredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottomUpPredictor</span></code></a> will be returned.</p>
<p>If this is a single-instance model, a <a class="reference internal" href="#sleap.nn.inference.SingleInstancePredictor" title="sleap.nn.inference.SingleInstancePredictor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SingleInstancePredictor</span></code></a> will be
returned.</p>
<p>If a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tracker</span></code> is specified, the predictor will also run identity tracking over
time.</p>
</p>
</dd>
</dl>
<p>See also: TopDownPredictor, BottomUpPredictor, SingleInstancePredictor</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.main">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">main</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L5492-L5708"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.main" title="Permalink to this definition">#</a></dt>
<dd><p>Entrypoint for <code class="xref py py-obj docutils literal notranslate"><span class="pre">sleap-track</span></code> CLI for running inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong>  A list of arguments to be passed into sleap-track.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="sleap.nn.inference.make_model_movenet">
<span class="sig-prename descclassname"><span class="pre">sleap.nn.inference.</span></span><span class="sig-name descname"><span class="pre">make_model_movenet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="reference external" href="https://github.com/talmolab/sleap/blob/v1.4.1a2/sleap/nn/inference.py#L4545-L4579"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sleap.nn.inference.make_model_movenet" title="Permalink to this definition">#</a></dt>
<dd><p>Load a MoveNet model by name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_name</strong>  Name of the model (lightning or thunder)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tf.keras.Model ready for inference.</p>
</dd>
</dl>
</dd></dl>

</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.paf_scorer"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.paf_scorer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.cm_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.cm_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.paf_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.paf_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.return_confmaps"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.return_pafs"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_pafs</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.return_paf_graph"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.return_paf_graph</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.pafs_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.pafs_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.offsets_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.find_peaks"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.find_peaks()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceLayer.forward_pass"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceLayer.forward_pass()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceModel"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceModel.bottomup_layer"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceModel.bottomup_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">BottomUpInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.cm_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.cm_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_output_stride"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.class_maps_output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_confmaps"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.return_class_maps"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.return_class_maps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.class_maps_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.class_maps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.offsets_ind"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.find_peaks"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.find_peaks()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceLayer.forward_pass"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceLayer.forward_pass()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel.inference_layer"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceModel.inference_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.config"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.model"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.tracks"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.tracks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpMultiClassPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">BottomUpMultiClassPredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.bottomup_config"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.bottomup_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.bottomup_model"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.bottomup_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.tracker"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.tracker</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.max_edge_length_ratio"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.max_edge_length_ratio</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.dist_penalty_weight"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.dist_penalty_weight</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.paf_line_points"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.paf_line_points</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.min_line_scores"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.min_line_scores</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.max_instances"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.max_instances</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.BottomUpPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">BottomUpPredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop"><code class="docutils literal notranslate"><span class="pre">CentroidCrop</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.keras_model"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.crop_size"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.crop_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.input_scale"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.output_stride"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.peak_threshold"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.refinement"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.return_confmaps"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.offsets_ind"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.return_crops"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.return_crops</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.max_instances"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.max_instances</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCrop.call"><code class="docutils literal notranslate"><span class="pre">CentroidCrop.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCropGroundTruth"><code class="docutils literal notranslate"><span class="pre">CentroidCropGroundTruth</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCropGroundTruth.crop_size"><code class="docutils literal notranslate"><span class="pre">CentroidCropGroundTruth.crop_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidCropGroundTruth.call"><code class="docutils literal notranslate"><span class="pre">CentroidCropGroundTruth.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidInferenceModel"><code class="docutils literal notranslate"><span class="pre">CentroidInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidInferenceModel.centroid_crop"><code class="docutils literal notranslate"><span class="pre">CentroidInferenceModel.centroid_crop</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.CentroidInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">CentroidInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.keras_model"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.input_scale"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.output_stride"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.peak_threshold"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.refinement"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.return_confmaps"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.offsets_ind"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaks.call"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaks.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaksGroundTruth"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaksGroundTruth</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.FindInstancePeaksGroundTruth.call"><code class="docutils literal notranslate"><span class="pre">FindInstancePeaksGroundTruth.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer"><code class="docutils literal notranslate"><span class="pre">InferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.ensure_grayscale"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.ensure_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.ensure_float"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.ensure_float</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceLayer.preprocess"><code class="docutils literal notranslate"><span class="pre">InferenceLayer.preprocess()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel"><code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel.export_model"><code class="docutils literal notranslate"><span class="pre">InferenceModel.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel.predict"><code class="docutils literal notranslate"><span class="pre">InferenceModel.predict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.InferenceModel.predict_on_batch"><code class="docutils literal notranslate"><span class="pre">InferenceModel.predict_on_batch()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.model_name"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.model_name</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.ensure_grayscale"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.ensure_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.ensure_float"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.ensure_float</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceModel"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceModel.inference_layer"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceModel.inference_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">MoveNetInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.model_name"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.model_name</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.MoveNetPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">MoveNetPredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor"><code class="docutils literal notranslate"><span class="pre">Predictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.export_model"><code class="docutils literal notranslate"><span class="pre">Predictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.from_model_paths"><code class="docutils literal notranslate"><span class="pre">Predictor.from_model_paths()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">Predictor.is_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">Predictor.make_pipeline()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.predict"><code class="docutils literal notranslate"><span class="pre">Predictor.predict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.Predictor.report_period"><code class="docutils literal notranslate"><span class="pre">Predictor.report_period</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.RateColumn"><code class="docutils literal notranslate"><span class="pre">RateColumn</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.RateColumn.render"><code class="docutils literal notranslate"><span class="pre">RateColumn.render()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.keras_model"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.input_scale"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.pad_to_stride"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.pad_to_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.output_stride"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.peak_threshold"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.refinement"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.return_confmaps"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.offsets_ind"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceLayer.call"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceModel"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceModel.single_instance_layer"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceModel.single_instance_layer</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstanceInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">SingleInstanceInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.confmap_config"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.confmap_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.confmap_model"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.confmap_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.export_model"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.SingleInstancePredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">SingleInstancePredictor.is_grayscale</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel.centroid_crop"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel.centroid_crop</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel.instance_peaks"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel.instance_peaks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">TopDownInferenceModel.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.keras_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.keras_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.input_scale"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.input_scale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.output_stride"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.output_stride</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.peak_threshold"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.refinement"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_confmaps"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.return_confmaps</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.return_class_vectors"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.return_class_vectors</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.confmaps_ind"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.confmaps_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.offsets_ind"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.offsets_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.class_vectors_ind"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.class_vectors_ind</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.optimal_grouping"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.optimal_grouping</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassFindPeaks.call"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassFindPeaks.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.centroid_crop"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.centroid_crop</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.instance_peaks"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.instance_peaks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.call"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.call()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassInferenceModel.export_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassInferenceModel.export_model()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.centroid_config"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.centroid_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.centroid_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.centroid_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.confmap_config"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.confmap_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.confmap_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.confmap_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.tracker"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.tracker</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.tracks"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.tracks</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.export_model"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.is_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownMultiClassPredictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownMultiClassPredictor.make_pipeline()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.centroid_config"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.centroid_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.centroid_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.centroid_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.confmap_config"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.confmap_config</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.confmap_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.confmap_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.inference_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.inference_model</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.pipeline</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.tracker"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.tracker</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.batch_size"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.peak_threshold"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.peak_threshold</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.integral_refinement"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.integral_refinement</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.integral_patch_size"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.integral_patch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.max_instances"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.max_instances</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.export_model"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.export_model()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.from_trained_models"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.from_trained_models()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.is_grayscale"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.is_grayscale</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.TopDownPredictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">TopDownPredictor.make_pipeline()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor"><code class="docutils literal notranslate"><span class="pre">VisualPredictor</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor.make_pipeline"><code class="docutils literal notranslate"><span class="pre">VisualPredictor.make_pipeline()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor.predict"><code class="docutils literal notranslate"><span class="pre">VisualPredictor.predict()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.VisualPredictor.safely_generate"><code class="docutils literal notranslate"><span class="pre">VisualPredictor.safely_generate()</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.export_cli"><code class="docutils literal notranslate"><span class="pre">export_cli()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.export_model"><code class="docutils literal notranslate"><span class="pre">export_model()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.find_head"><code class="docutils literal notranslate"><span class="pre">find_head()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.get_keras_model_path"><code class="docutils literal notranslate"><span class="pre">get_keras_model_path()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.get_model_output_stride"><code class="docutils literal notranslate"><span class="pre">get_model_output_stride()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.main"><code class="docutils literal notranslate"><span class="pre">main()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sleap.nn.inference.make_model_movenet"><code class="docutils literal notranslate"><span class="pre">make_model_movenet()</span></code></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SLEAP Developers
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 20192024, Talmo Lab.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>