{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training and inference using Google Drive",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murthylab/sleap-notebooks/blob/master/Training_and_inference_using_Google_Drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5xp-A8Oc80Q",
        "colab_type": "text"
      },
      "source": [
        "This notebook shows you how to run training and inference on your own SLEAP dataset using the command-line interface.\n",
        "\n",
        "You'll use [Google Drive](https://www.google.com/drive) for moving your data to and from Colab. We'll guide you through the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX9noEb8m8re",
        "colab_type": "text"
      },
      "source": [
        "# Installation\n",
        "\n",
        "Before we install SLEAP we need to set Colab to use TensorFlow 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hJvyI24KXlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5WL10cao-sc",
        "colab_type": "text"
      },
      "source": [
        "Let's confirm that we have a GPU available. This next line should return something like \"/device:GPU:0\". If you instead see an empty string as the result, go to \"Notebook settings\" in the \"Edit\" menu and select \"GPU\" as the hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I12Lk6TKZnn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34e1f203-74fc-41b3-83e7-3aed695f8264"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMjYpcVFqWgV"
      },
      "source": [
        "Now let's use `pip` to install SLEAP from PyPI.\n",
        "\n",
        "Note: This installation method should also work on other Linux machines, such as an HPC cluster, or on any system where you aren't planning to use a GPU. To use a GPU on a Windows machine you'll need to install using `conda`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUfnkxMtLcK3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4da8bc23-4209-4007-8507-607a30738f13"
      },
      "source": [
        "!pip install sleap==1.1.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sleap==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/52/e80875c50a649da56377c7884d5b937260b2310f8c2543dca9bf6c3c06d4/sleap-1.1.0a10-py3-none-any.whl (39.5MB)\n",
            "\u001b[K     |████████████████████████████████| 39.5MB 83kB/s \n",
            "\u001b[?25hCollecting numpy<1.19.0,>=1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 121kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (22.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (3.13)\n",
            "Collecting opencv-python-headless==4.2.0.34\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/2c/909a04b07360516953beaf6f66480bb6b84b817c6b300c1235bfb2901ad8/opencv_python_headless-4.2.0.34-cp36-cp36m-manylinux1_x86_64.whl (21.6MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6MB 105kB/s \n",
            "\u001b[?25hCollecting imgstore==0.2.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/bb/a1099d1564c1f85752251a9549037ce36021f2b318c896be2f2b067d7e9a/imgstore-0.2.9-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 53.6MB/s \n",
            "\u001b[?25hCollecting imgaug==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/df/5a3bba95b4600d5ca7aff072082ef0d9837056dd28cc4e738e7ce88dd8f8/imgaug-0.3.0-py2.py3-none-any.whl (819kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 51.8MB/s \n",
            "\u001b[?25hCollecting attrs==19.3\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
            "Collecting pykalman==0.9.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/62/a4adc4516bd5974aa5583090199dd4b78d1e87018d14e9279f72ccbf0b9b/pykalman-0.9.5.tar.gz (228kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 62.6MB/s \n",
            "\u001b[?25hCollecting jsonpickle==1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/07/07/c157520a3ebd166c8c24c6ae0ecae7c3968eb4653ff0e5af369bb82f004d/jsonpickle-1.2-py2.py3-none-any.whl\n",
            "Collecting tensorflow==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ad/769c195c72ac72040635c66cd9ba7b0f4b4fc1ac67e59b99fa6988446c22/tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 49kB/s \n",
            "\u001b[?25hCollecting qimage2ndarray==1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/16/fdd8930ef4f5795afc3cf89f056645ff012da828a4ddcc6a3d6d41edfb53/qimage2ndarray-1.8.tar.gz (183kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 59.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (2.10.0)\n",
            "Requirement already satisfied: scipy<=1.4.1 in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (0.16.2)\n",
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (0.22.2.post1)\n",
            "Collecting segmentation-models==1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Collecting cattrs==1.0.0rc\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/f6/30e2b78920dae271ba94cb74a808021d88840b156c424c029f6255b72d3e/cattrs-1.0.0rc0-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[?25hCollecting jsmin\n",
            "  Downloading https://files.pythonhosted.org/packages/17/73/615d1267a82ed26cd7c124108c3c61169d8e40c36d393883eaee3a561852/jsmin-2.2.2.tar.gz\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (0.11.1)\n",
            "Collecting PySide2==5.14.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/ea/4699f9a83069751b98b038733b3123f5774da939ebba29a601964280a756/PySide2-5.14.1-5.14.1-cp35.cp36.cp37.cp38-abi3-manylinux1_x86_64.whl (165.5MB)\n",
            "\u001b[K     |████████████████████████████████| 165.5MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (1.1.5)\n",
            "Collecting rich==9.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/60/765dc36f3623c22fd08f152bfae65cc9f0d815c05503ea50f7c189486d10/rich-9.10.0-py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 60.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from sleap==1.1.0a10) (5.4.8)\n",
            "Collecting python-rapidjson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/8f/50488049033aba6943659d7906a45947ea5b510b74e7d44ab9d7457e1710/python_rapidjson-1.0-cp36-cp36m-manylinux2010_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->sleap==1.1.0a10) (4.4.2)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1->sleap==1.1.0a10) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1->sleap==1.1.0a10) (0.10.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->sleap==1.1.0a10) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sleap==1.1.0a10) (1.0.0)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hCollecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Collecting shiboken2==5.14.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/9b/afca43974697e7b50ec22d3ad0c878a3d07eb89bfe75d341707ff2421772/shiboken2-5.14.1-5.14.1-cp35.cp36.cp37.cp38-abi3-manylinux1_x86_64.whl (847kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 49.7MB/s \n",
            "\u001b[?25hCollecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from rich==9.10.0->sleap==1.1.0a10) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from rich==9.10.0->sleap==1.1.0a10) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses<0.9,>=0.7; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from rich==9.10.0->sleap==1.1.0a10) (0.8)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.3.0->sleap==1.1.0a10) (2.4.7)\n",
            "Building wheels for collected packages: pykalman, qimage2ndarray, jsmin\n",
            "  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykalman: filename=pykalman-0.9.5-cp36-none-any.whl size=48464 sha256=a9f29ac5e417c8447035238754a9b2ab0d54e3d7792b92eb2f998c9da2f919d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/e8/6a/553d9832679cb74a8434fa597c3abdb07313e40054a0adf9ac\n",
            "  Building wheel for qimage2ndarray (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qimage2ndarray: filename=qimage2ndarray-1.8-cp36-none-any.whl size=11696 sha256=1699000301d530fa0739661ea993278e79c48812f313089881eea7f42bd55210\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/ef/1d/c77ef6d3d3fe72aa88f822a05e29b17e79914af69ddeff4c02\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsmin: filename=jsmin-2.2.2-cp36-none-any.whl size=13921 sha256=2e73dbea2cb2472654d5f25faa8b0dbe84c9f4bd24e14cf94243f9b3aa20839d\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/f4/de/9667d84f759289edf5442220997c6d4334637a6bb2a7b90f73\n",
            "Successfully built pykalman qimage2ndarray jsmin\n",
            "Installing collected packages: numpy, opencv-python-headless, imgstore, imgaug, attrs, pykalman, jsonpickle, tensorflow-estimator, tensorflow, qimage2ndarray, scikit-video, keras-applications, efficientnet, image-classifiers, segmentation-models, cattrs, jsmin, shiboken2, PySide2, colorama, commonmark, rich, python-rapidjson, sleap\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: attrs 20.3.0\n",
            "    Uninstalling attrs-20.3.0:\n",
            "      Successfully uninstalled attrs-20.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed PySide2-5.14.1 attrs-19.3.0 cattrs-1.0.0rc0 colorama-0.4.4 commonmark-0.9.1 efficientnet-1.0.0 image-classifiers-1.0.0 imgaug-0.3.0 imgstore-0.2.9 jsmin-2.2.2 jsonpickle-1.2 keras-applications-1.0.8 numpy-1.18.5 opencv-python-headless-4.2.0.34 pykalman-0.9.5 python-rapidjson-1.0 qimage2ndarray-1.8 rich-9.10.0 scikit-video-1.1.11 segmentation-models-1.0.1 shiboken2-5.14.1 sleap-1.1.0a10 tensorflow-2.3.1 tensorflow-estimator-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq7jrgUksLtR"
      },
      "source": [
        "## Getting your training data into Colab\n",
        "\n",
        "You'll need to get your training data into Colab. The easiest way to do this is to export a self-contained **training package** from SLEAP and copy that on to [Google Drive](https://www.google.com/drive).\n",
        "\n",
        "Let's first mount your Google Drive so that it can be accessed from Colab. You'll be prompted to log into your Google account, give Colab access, and the copy an authorization code into a field below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBWjF4jpMG2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b95967-c85a-4983-9896-84e2a41546d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQhv_gsdJzaq"
      },
      "source": [
        "Now let's create a training package and copy it into your Google Drive.\n",
        "\n",
        "A training package contains both labeled data as well as the labeled images which will be used for training. One advantage to training packages is that it doesn't depend on paths to other files (i.e., videos) to be messed up when you copy your project to another volume.\n",
        "\n",
        "See [this guide](https://sleap.ai/guides/training-package.html) for exporting a training package from SLEAP.\n",
        "\n",
        "\n",
        "\n",
        "The following cell sets your current working directory to the directory with your training package. This will ensure that the output from training (i.e., the models) and from interence (i.e., predictions) will all be saved in this directory.\n",
        "\n",
        "**Important**: For this demo, I'll assume you have a `sleap` directory in the root of your Google drive and you place the exported training package in that directory with the filename `colab.pkg.slp`. If you placed your training pckage somewhere else, you'll need to adjust the path below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9umui-gI2rBz"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/sleap\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-sr67av5uu"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now you're ready to train a model! We'll use the command-line interface for training, and train a model for confidence maps using the default **training profile**. The training profile determines the model architecture, the learning rate for training, and other training hyperparameters.\n",
        "\n",
        "When you start running this cell, you'll see the training parameters listed and then you'll see the training and validation loss for each training epoch.\n",
        "\n",
        "If you're happy with the validation loss you see for an epoch during training, you're welcome to stop training by clicking the stop button next to the notebook cell running training. The version of the model with the lowest validation loss is saved during training, and that's what will be used for inference. If you don't stop training, it will run for 200 epochs, or until validation loss fails to improve for some number of epochs (controlled by the `early_stopping` parameter in the training profile).\n",
        "\n",
        "**Important**: If your training package isn't named `colab.pkg.slp`, you'll need to adjust the name below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKf6qzMqNBUi"
      },
      "source": [
        "!sleap-train baseline_medium_rf.bottomup.json colab.pkg.slp --run_name \"colab_demo.bottomup\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whOf8PaFxYbt"
      },
      "source": [
        "Once training finishes, you'll have a trained model for confidence maps on your Google Drive. There will be a `models/` directory inside your `sleap/` directory (or wherever you had the training package), and inside this there will be a `colab_demo.bottomup` directory (the name of this directory was set by the `--run_name` parameter). \n",
        "\n",
        "This `colab_demo.bottomup` directory contains all the files SLEAP needs to use this model. You can copy it to a local drive if you want to use it for running inference from the SLEAP GUI, copy it to a network drive if you want to run inference from an HPC cluster, or leave it on your Google Drive if you want to run inference on Colab... as we'll do below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7JUp9P840qB"
      },
      "source": [
        "## Training other models\n",
        "\n",
        "The **bottomup** model you trained above can be used for \"bottom up\" inference. You can also train a **centroid** model and a **centered instance** model for \"top down\" inference. See [here](https://sleap.ai/#getting-started-with-sleap) for more information about these two different approaches.\n",
        "\n",
        "Here's how to train centroid and centered instance models using the default training settings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZVftKcJ46jU"
      },
      "source": [
        "!sleap-train baseline_medium_rf.topdown.json --run_name \"colab_demo.topdown_confmaps\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsPTDnkW49-5"
      },
      "source": [
        "!sleap-train baseline.centroid.json colab.pkg.slp --run_name \"colab_demo.centroid\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsKUX661xFK"
      },
      "source": [
        "# Inference\n",
        "\n",
        "At this point you should have SLEAP installed, your Google Drive mounted, and trained models saved on your Google Drive. If you've been working through the notebook, you should have a `models` subdirectory inside your current working directory. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01HDohE5upwQ"
      },
      "source": [
        "!ls models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNi260mJuyJ7"
      },
      "source": [
        "We'll also need a video for which we want predictions. Copy the video onto your Google drive.\n",
        "\n",
        "For this demo we'll just get predictions for the first 200 frames (or you can adjust the `--frames` parameter below or remove it to run on the whole video).\n",
        "\n",
        "**Important**: If your video is not named `colab_demo.mp4`, change this in the following cell to match the name of your video. If you trained top-down models and not a bottom-up model, see the end of the notebook for how to run inference with the pair of top-down models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLtjtq9E1Znr"
      },
      "source": [
        "!sleap-track colab_demo.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m models/colab_demo.bottomup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzObCUToEqwA"
      },
      "source": [
        "When inference is finished, it will save the predictions in a file which can be opened in the GUI as a SLEAP project file. The file will be in the same directory as the video and the filename will be `{video filename}.predictions.slp`.\n",
        "\n",
        "Let's inspect the predictions file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPfmNMSt-vS7"
      },
      "source": [
        "!sleap-inspect colab_demo.mp4.predictions.slp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoJ2kNBK-w6k"
      },
      "source": [
        "You can copy this file from your Google Drive to a local drive and open it in the SLEAP GUI app (or open it directly if you have your Google Drive mounted on your local machine). If the video is in the same directory as the predictions file, SLEAP will automatically find it; otherwise, you'll be prompted to locate the video (since the path to the video on your local machine will be different than the path to the video on Colab)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf-MsD7fv5Wy"
      },
      "source": [
        "## Inference parameters\n",
        "\n",
        "One important option when running inference is whether (and how) you want to track instance identities. If you omit `--tracking.tracker flow` then the identities will not be tracked. Tracking methods/options are explained [here](https://sleap.ai/guides/proofreading.html#tracking-methods).\n",
        "\n",
        "You can see all of the command-line arguments by calling `sleap-track` with the `--help` argument, like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hh4ogd9wtxP"
      },
      "source": [
        "!sleap-track --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-NoJOFvYHM"
      },
      "source": [
        "## Inference with top-down models\n",
        "\n",
        "If you trained the pair of models needed for top-down inference, you can call `sleap-track` with `-m path/to/model` for each model, like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPKnMc1qvim7"
      },
      "source": [
        "!sleap-track colab_demo.video.mp4 \\\n",
        "    --frames 0-200 \\\n",
        "    --tracking.tracker simple \\\n",
        "    -m models/colab_demo.topdown_confmaps \\\n",
        "    -m models/colab_demo.centroid"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}